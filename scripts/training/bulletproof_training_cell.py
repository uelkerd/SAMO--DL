# ğŸš€ BULLETPROOF TRAINING CELL - RUN IN FRESH KERNEL
# Runtime â†’ Change runtime type â†’ GPU (T4 or V100)
# Kernel â†’ Restart and run all

print("ğŸš€ BULLETPROOF TRAINING FOR REQ-DL-012")
print("=" * 50)

# Step 1: Clear everything and validate environment
import os
import sys
import json
import pickle
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from datasets import load_dataset
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score
from sklearn.preprocessing import LabelEncoder
from transformers import AutoModel, AutoTokenizer
from pathlib import Path

print("âœ… Imports successful")

# Clear GPU memory
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    print(f"âœ… GPU memory cleared: {torch.cuda.get_device_name()}")
else:
    print("âš ï¸ CUDA not available, using CPU")

# Test basic operations
try:
    test_tensor = torch.randn(2, 3)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    test_tensor.to(device)
    print("âœ… Basic tensor operations work")
except Exception as e:
    print(f"âŒ Basic tensor operations failed: {e}")
    raise

# Step 2: Ensure we are at the repository root
def _find_repo_root(start: Path) -> Path:
    for d in [start] + list(start.parents):
        if (d / "src").exists():
            return d
    return start

REPO_ROOT = _find_repo_root(Path(__file__).resolve())
os.chdir(str(REPO_ROOT))

# Step 3: Create unified label encoder
print("\nğŸ”§ Creating unified label encoder...")

go_emotions = load_dataset("go_emotions", "simplified")
with open('data/journal_test_dataset.json', 'r') as f:
    journal_entries = json.load(f)
journal_df = pd.DataFrame(journal_entries)

# Extract labels
go_labels = set()
for example in go_emotions['train']:
    if example['labels']:
        go_labels.update(example['labels'])

journal_labels = set(journal_df['emotion'].unique())

# Find common labels
common_labels = sorted(list(go_labels.intersection(journal_labels)))
if not common_labels:
    print("âš ï¸ No common labels found! Using all labels...")
    # FIX: Convert to strings before union to avoid type comparison issues
    all_go_labels = [str(label) for label in go_labels]
    all_journal_labels = [str(label) for label in journal_labels]
    common_labels = sorted(list(set(all_go_labels + all_journal_labels)))

print(f"ğŸ“Š Using {len(common_labels)} labels: {common_labels}")

# Create encoder
label_encoder = LabelEncoder()
label_encoder.fit(common_labels)
label_to_id = {label: idx for idx, label in enumerate(label_encoder.classes_)}
id_to_label = {idx: label for label, idx in label_to_id.items()}

print(f"âœ… Label encoder created with {len(label_encoder.classes_)} classes")

# Step 4: Prepare filtered data
print("\nğŸ“Š Preparing filtered data...")

valid_labels = set(label_encoder.classes_)

# Filter GoEmotions data
go_texts = []
go_labels = []
for example in go_emotions['train']:
    if example['labels']:
        for label in example['labels']:
            if label in valid_labels:
                go_texts.append(example['text'])
                go_labels.append(label_to_id[label])
                break

# Filter journal data
journal_texts = []
journal_labels = []
for _, row in journal_df.iterrows():
    if row['emotion'] in valid_labels:
        journal_texts.append(row['content'])
        journal_labels.append(label_to_id[row['emotion']])

print(f"ğŸ“Š Filtered GoEmotions: {len(go_texts)} samples")
print(f"ğŸ“Š Filtered Journal: {len(journal_texts)} samples")

# Validate label ranges
go_label_range = (min(go_labels), max(go_labels)) if go_labels else (0, 0)
journal_label_range = (min(journal_labels), max(journal_labels)) if journal_labels else (0, 0)
expected_range = (0, len(label_encoder.classes_) - 1)

print(f"ğŸ“Š GoEmotions label range: {go_label_range}")
print(f"ğŸ“Š Journal label range: {journal_label_range}")
print(f"ğŸ“Š Expected range: {expected_range}")

if go_label_range[0] < expected_range[0] or go_label_range[1] > expected_range[1]:
    raise ValueError("âŒ GoEmotions labels out of range!")

if journal_label_range[0] < expected_range[0] or journal_label_range[1] > expected_range[1]:
    raise ValueError("âŒ Journal labels out of range!")

print("âœ… All labels within expected range")

# Step 5: Create simple dataset class
class SimpleEmotionDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
        
        # Validate data
        if len(texts) != len(labels):
            raise ValueError(f"Texts and labels have different lengths: {len(texts)} vs {len(labels)}")
        
        # Validate labels
        for i, label in enumerate(labels):
            if not isinstance(label, int) or label < 0:
                raise ValueError(f"Invalid label at index {i}: {label}")
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]
        
        # Validate inputs
        if not isinstance(text, str) or not text.strip():
            raise ValueError(f"Invalid text at index {idx}")
        
        if not isinstance(label, int) or label < 0:
            raise ValueError(f"Invalid label at index {idx}: {label}")
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

# Step 6: Create simple model
class SimpleEmotionClassifier(nn.Module):
    def __init__(self, model_name="bert-base-uncased", num_labels=None):
        super().__init__()
        
        if num_labels is None or num_labels <= 0:
            raise ValueError(f"Invalid num_labels: {num_labels}")
        
        self.num_labels = num_labels
        self.bert = AutoModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(0.3)
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)
        
        print(f"âœ… Model initialized with {num_labels} labels")
    
    def forward(self, input_ids, attention_mask):
        # Validate inputs
        if input_ids.dim() != 2:
            raise ValueError(f"Expected input_ids to be 2D, got {input_ids.dim()}D")
        
        if attention_mask.dim() != 2:
            raise ValueError(f"Expected attention_mask to be 2D, got {attention_mask.dim()}D")
        
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        logits = self.classifier(self.dropout(pooled_output))
        
        # Validate outputs
        if logits.shape[-1] != self.num_labels:
            raise ValueError(f"Expected {self.num_labels} output classes, got {logits.shape[-1]}")
        
        return logits

# Step 7: Setup training
print("\nğŸš€ Setting up training...")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… Using device: {device}")

# Initialize tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
num_labels = len(label_encoder.classes_)
model = SimpleEmotionClassifier(model_name="bert-base-uncased", num_labels=num_labels)
model = model.to(device)

# Create datasets
go_dataset = SimpleEmotionDataset(go_texts, go_labels, tokenizer)
journal_dataset = SimpleEmotionDataset(journal_texts, journal_labels, tokenizer)

# Split journal data
journal_train_texts, journal_val_texts, journal_train_labels, journal_val_labels = train_test_split(
    journal_texts, journal_labels, test_size=0.3, random_state=42, stratify=journal_labels
)

journal_train_dataset = SimpleEmotionDataset(journal_train_texts, journal_train_labels, tokenizer)
journal_val_dataset = SimpleEmotionDataset(journal_val_texts, journal_val_labels, tokenizer)

# Create dataloaders
go_loader = DataLoader(go_dataset, batch_size=8, shuffle=True)
journal_train_loader = DataLoader(journal_train_dataset, batch_size=8, shuffle=True)
journal_val_loader = DataLoader(journal_val_dataset, batch_size=8, shuffle=False)

print(f"âœ… Training samples: {len(go_dataset)} GoEmotions + {len(journal_train_dataset)} Journal")
print(f"âœ… Validation samples: {len(journal_val_dataset)} Journal")

# Step 8: Training loop
print("\nğŸš€ Starting training...")

optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
criterion = nn.CrossEntropyLoss()

num_epochs = 3  # Reduced for testing
best_f1 = 0.0

for epoch in range(num_epochs):
    print(f"\nğŸ”„ Epoch {epoch + 1}/{num_epochs}")
    
    # Training
    model.train()
    total_loss = 0
    num_batches = 0
    
    # Train on GoEmotions
    print("  ğŸ“š Training on GoEmotions...")
    for i, batch in enumerate(go_loader):
        try:
            # Validate batch
            if 'input_ids' not in batch or 'attention_mask' not in batch or 'labels' not in batch:
                print(f"âš ï¸ Invalid batch structure at batch {i}")
                continue
            
            # Move to device with validation
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            # Validate labels
            if torch.any(labels >= num_labels) or torch.any(labels < 0):
                print(f"âš ï¸ Invalid labels in batch {i}: {labels}")
                continue
            
            # Forward pass
            optimizer.zero_grad()
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            num_batches += 1
            
            if i % 50 == 0:
                print(f"    Batch {i}/{len(go_loader)}, Loss: {loss.item():.4f}")
                
        except Exception as e:
            print(f"âŒ Error in batch {i}: {e}")
            continue
    
    # Train on journal data
    print("  ğŸ“ Training on journal data...")
    for i, batch in enumerate(journal_train_loader):
        try:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            if torch.any(labels >= num_labels) or torch.any(labels < 0):
                continue
            
            optimizer.zero_grad()
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            num_batches += 1
            
            if i % 10 == 0:
                print(f"    Batch {i}/{len(journal_train_loader)}, Loss: {loss.item():.4f}")
                
        except Exception as e:
            print(f"âŒ Error in journal batch {i}: {e}")
            continue
    
    # Validation
    print("  ğŸ¯ Validating...")
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for batch in journal_val_loader:
            try:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)
                
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                preds = torch.argmax(outputs, dim=1)
                
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                
            except Exception as e:
                print(f"âŒ Error in validation batch: {e}")
                continue
    
    # Calculate metrics
    if all_preds and all_labels:
        f1_macro = f1_score(all_labels, all_preds, average='macro')
        accuracy = accuracy_score(all_labels, all_preds)
        
        avg_loss = total_loss / num_batches if num_batches > 0 else 0
        
        print(f"  ğŸ“Š Epoch {epoch + 1} Results:")
        print(f"    Average Loss: {avg_loss:.4f}")
        print(f"    Validation F1 (Macro): {f1_macro:.4f}")
        print(f"    Validation Accuracy: {accuracy:.4f}")
        
        # Save best model
        if f1_macro > best_f1:
            best_f1 = f1_macro
            torch.save(model.state_dict(), 'best_simple_model.pth')
            print(f"    ğŸ’¾ New best model saved! F1: {best_f1:.4f}")
    
    # Clear GPU cache
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

print(f"\nğŸ† Training completed! Best F1 Score: {best_f1:.4f}")

# Step 9: Save results
results = {
    'best_f1': best_f1,
    'num_labels': num_labels,
    'target_achieved': best_f1 >= 0.7,
    'go_samples': len(go_texts),
    'journal_samples': len(journal_texts)
}

with open('simple_training_results.json', 'w') as f:
    json.dump(results, f, indent=2)

print("\nâœ… Training completed successfully!")
print(f"ğŸ“Š Final F1 Score: {best_f1:.4f}")
print(f"ğŸ¯ Target Met: {'âœ…' if best_f1 >= 0.7 else 'âŒ'}")

# Download results
from google.colab import files
files.download('best_simple_model.pth')
files.download('simple_training_results.json')

print("\nğŸ‰ BULLETPROOF TRAINING COMPLETED!")
print("ğŸ“ Files downloaded: best_simple_model.pth, simple_training_results.json")