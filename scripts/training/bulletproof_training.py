#!/usr/bin/env python3
"""Bulletproof training script for REQ-DL-012 that handles notebook state corruption.
This script can be run in a fresh kernel and will validate everything step by step.
"""

import json
import logging
import pickle
import sys

import pandas as pd
import torch
from datasets import load_dataset
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch import nn
from torch.utils.data import DataLoader, Dataset
from transformers import AutoModel, AutoTokenizer

# Setup logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def validate_environment():
    """Validate the environment and clear any corrupted state."""
    logger.info("üîç Validating environment...")

    # Clear GPU memory
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        logger.info("‚úÖ GPU memory cleared")

    # Check CUDA
    if torch.cuda.is_available():
        logger.info(f"‚úÖ CUDA available: {torch.cuda.get_device_name()}")
        logger.info(
            f"‚úÖ CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB"
        )
    else:
        logger.warning("‚ö†Ô∏è CUDA not available, using CPU")

    # Test basic operations
    try:
        test_tensor = torch.randn(2, 3)
        test_tensor.to("cuda" if torch.cuda.is_available() else "cpu")
        logger.info("‚úÖ Basic tensor operations work")
    except Exception as e:
        logger.error(f"‚ùå Basic tensor operations failed: {e}")
        return False

    return True


def create_unified_label_encoder():
    """Create a unified label encoder for both datasets."""
    logger.info("üîß Creating unified label encoder...")

    # Load datasets
    go_emotions = load_dataset("go_emotions", "simplified")
    with open("data/journal_test_dataset.json") as f:
        journal_entries = json.load(f)
    journal_df = pd.DataFrame(journal_entries)

    # Extract labels
    go_labels = set()
    for example in go_emotions["train"]:
        if example["labels"]:
            go_labels.update(example["labels"])

    journal_labels = set(journal_df["emotion"].unique())

    # Find common labels
    common_labels = sorted(list(go_labels.intersection(journal_labels)))
    if not common_labels:
        logger.warning("‚ö†Ô∏è No common labels found! Using all labels...")
        common_labels = sorted(list(go_labels.union(journal_labels)))

    logger.info(f"üìä Using {len(common_labels)} labels: {common_labels}")

    # Create encoder
    label_encoder = LabelEncoder()
    label_encoder.fit(common_labels)

    # Save encoder
    with open("unified_label_encoder.pkl", "wb") as f:
        pickle.dump(label_encoder, f)

    # Save mappings
    label_to_id = {label: idx for idx, label in enumerate(label_encoder.classes_)}
    id_to_label = {idx: label for label, idx in label_to_id.items()}

    with open("label_mappings.json", "w") as f:
        json.dump(
            {
                "label_to_id": label_to_id,
                "id_to_label": id_to_label,
                "num_labels": len(label_encoder.classes_),
                "classes": label_encoder.classes_.tolist(),
            },
            f,
            indent=2,
        )

    logger.info(f"‚úÖ Label encoder created with {len(label_encoder.classes_)} classes")
    return label_encoder, label_to_id, id_to_label


def prepare_filtered_data(label_encoder, label_to_id):
    """Prepare filtered data using only common labels."""
    logger.info("üìä Preparing filtered data...")

    # Load datasets
    go_emotions = load_dataset("go_emotions", "simplified")
    with open("data/journal_test_dataset.json") as f:
        journal_entries = json.load(f)
    journal_df = pd.DataFrame(journal_entries)

    valid_labels = set(label_encoder.classes_)

    # Filter GoEmotions data
    go_texts = []
    go_labels = []
    for example in go_emotions["train"]:
        if example["labels"]:
            for label in example["labels"]:
                if label in valid_labels:
                    go_texts.append(example["text"])
                    go_labels.append(label_to_id[label])
                    break

    # Filter journal data
    journal_texts = []
    journal_labels = []
    for _, row in journal_df.iterrows():
        if row["emotion"] in valid_labels:
            journal_texts.append(row["content"])
            journal_labels.append(label_to_id[row["emotion"]])

    logger.info(f"üìä Filtered GoEmotions: {len(go_texts)} samples")
    logger.info(f"üìä Filtered Journal: {len(journal_texts)} samples")

    # Validate label ranges - FIX: Convert to integers for comparison
    if go_labels:
        go_label_range = (min(go_labels), max(go_labels))
    else:
        go_label_range = (0, 0)

    if journal_labels:
        journal_label_range = (min(journal_labels), max(journal_labels))
    else:
        journal_label_range = (0, 0)

    expected_range = (0, len(label_encoder.classes_) - 1)

    logger.info(f"üìä GoEmotions label range: {go_label_range}")
    logger.info(f"üìä Journal label range: {journal_label_range}")
    logger.info(f"üìä Expected range: {expected_range}")

    if go_label_range[0] < expected_range[0] or go_label_range[1] > expected_range[1]:
        logger.error("‚ùå GoEmotions labels out of range!")
        return None, None, None, None

    if (
        journal_label_range[0] < expected_range[0]
        or journal_label_range[1] > expected_range[1]
    ):
        logger.error("‚ùå Journal labels out of range!")
        return None, None, None, None

    logger.info("‚úÖ All labels within expected range")
    return go_texts, go_labels, journal_texts, journal_labels


class SimpleEmotionDataset(Dataset):
    """Simple dataset class with validation."""

    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

        # Validate data
        if len(texts) != len(labels):
            raise ValueError(
                f"Texts and labels have different lengths: {len(texts)} vs {len(labels)}"
            )

        # Validate labels
        for i, label in enumerate(labels):
            if not isinstance(label, int) or label < 0:
                raise ValueError(f"Invalid label at index {i}: {label}")

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]

        # Validate inputs
        if not isinstance(text, str) or not text.strip():
            raise ValueError(f"Invalid text at index {idx}")

        if not isinstance(label, int) or label < 0:
            raise ValueError(f"Invalid label at index {idx}: {label}")

        encoding = self.tokenizer(
            text,
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors="pt",
        )

        return {
            "input_ids": encoding["input_ids"].flatten(),
            "attention_mask": encoding["attention_mask"].flatten(),
            "labels": torch.tensor(label, dtype=torch.long),
        }


class SimpleEmotionClassifier(nn.Module):
    """Simple emotion classifier with validation."""

    def __init__(self, model_name="bert-base-uncased", num_labels=None):
        super().__init__()

        if num_labels is None or num_labels <= 0:
            raise ValueError(f"Invalid num_labels: {num_labels}")

        self.num_labels = num_labels
        self.bert = AutoModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(0.3)
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)

        logger.info(f"‚úÖ Model initialized with {num_labels} labels")

    def forward(self, input_ids, attention_mask):
        # Validate inputs
        if input_ids.dim() != 2:
            raise ValueError(f"Expected input_ids to be 2D, got {input_ids.dim()}D")

        if attention_mask.dim() != 2:
            raise ValueError(
                f"Expected attention_mask to be 2D, got {attention_mask.dim()}D"
            )

        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        logits = self.classifier(self.dropout(pooled_output))

        # Validate outputs
        if logits.shape[-1] != self.num_labels:
            raise ValueError(
                f"Expected {self.num_labels} output classes, got {logits.shape[-1]}"
            )

        return logits


def train_model_simple(go_texts, go_labels, journal_texts, journal_labels, num_labels):
    """Simple training function with comprehensive validation."""
    logger.info("üöÄ Starting simple training...")

    # Setup device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"‚úÖ Using device: {device}")

    # Initialize tokenizer and model
    tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
    model = SimpleEmotionClassifier(
        model_name="bert-base-uncased", num_labels=num_labels
    )
    model = model.to(device)

    # Create datasets
    go_dataset = SimpleEmotionDataset(go_texts, go_labels, tokenizer)
    journal_dataset = SimpleEmotionDataset(journal_texts, journal_labels, tokenizer)

    # Split journal data
    journal_train_texts, journal_val_texts, journal_train_labels, journal_val_labels = (
        train_test_split(
            journal_texts,
            journal_labels,
            test_size=0.3,
            random_state=42,
            stratify=journal_labels,
        )
    )

    journal_train_dataset = SimpleEmotionDataset(
        journal_train_texts, journal_train_labels, tokenizer
    )
    journal_val_dataset = SimpleEmotionDataset(
        journal_val_texts, journal_val_labels, tokenizer
    )

    # Create dataloaders
    go_loader = DataLoader(go_dataset, batch_size=8, shuffle=True)
    journal_train_loader = DataLoader(journal_train_dataset, batch_size=8, shuffle=True)
    journal_val_loader = DataLoader(journal_val_dataset, batch_size=8, shuffle=False)

    logger.info(
        f"‚úÖ Training samples: {len(go_dataset)} GoEmotions + {len(journal_train_dataset)} Journal"
    )
    logger.info(f"‚úÖ Validation samples: {len(journal_val_dataset)} Journal")

    # Training setup
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
    criterion = nn.CrossEntropyLoss()

    # Training loop
    num_epochs = 3  # Reduced for testing
    best_f1 = 0.0

    for epoch in range(num_epochs):
        logger.info(f"üîÑ Epoch {epoch + 1}/{num_epochs}")

        # Training
        model.train()
        total_loss = 0
        num_batches = 0

        # Train on GoEmotions
        logger.info("  üìö Training on GoEmotions...")
        for i, batch in enumerate(go_loader):
            try:
                # Validate batch
                if (
                    "input_ids" not in batch
                    or "attention_mask" not in batch
                    or "labels" not in batch
                ):
                    logger.warning(f"‚ö†Ô∏è Invalid batch structure at batch {i}")
                    continue

                # Move to device with validation
                input_ids = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                labels = batch["labels"].to(device)

                # Validate labels
                if torch.any(labels >= num_labels) or torch.any(labels < 0):
                    logger.warning(f"‚ö†Ô∏è Invalid labels in batch {i}: {labels}")
                    continue

                # Forward pass
                optimizer.zero_grad()
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                total_loss += loss.item()
                num_batches += 1

                if i % 50 == 0:
                    logger.info(
                        f"    Batch {i}/{len(go_loader)}, Loss: {loss.item():.4f}"
                    )

            except Exception as e:
                logger.error(f"‚ùå Error in batch {i}: {e}")
                continue

        # Train on journal data
        logger.info("  üìù Training on journal data...")
        for i, batch in enumerate(journal_train_loader):
            try:
                input_ids = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                labels = batch["labels"].to(device)

                if torch.any(labels >= num_labels) or torch.any(labels < 0):
                    continue

                optimizer.zero_grad()
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                total_loss += loss.item()
                num_batches += 1

                if i % 10 == 0:
                    logger.info(
                        f"    Batch {i}/{len(journal_train_loader)}, Loss: {loss.item():.4f}"
                    )

            except Exception as e:
                logger.error(f"‚ùå Error in journal batch {i}: {e}")
                continue

        # Validation
        logger.info("  üéØ Validating...")
        model.eval()
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for batch in journal_val_loader:
                try:
                    input_ids = batch["input_ids"].to(device)
                    attention_mask = batch["attention_mask"].to(device)
                    labels = batch["labels"].to(device)

                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                    preds = torch.argmax(outputs, dim=1)

                    all_preds.extend(preds.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())

                except Exception as e:
                    logger.error(f"‚ùå Error in validation batch: {e}")
                    continue

        # Calculate metrics
        if all_preds and all_labels:
            f1_macro = f1_score(all_labels, all_preds, average="macro")
            accuracy = accuracy_score(all_labels, all_preds)

            avg_loss = total_loss / num_batches if num_batches > 0 else 0

            logger.info(f"  üìä Epoch {epoch + 1} Results:")
            logger.info(f"    Average Loss: {avg_loss:.4f}")
            logger.info(f"    Validation F1 (Macro): {f1_macro:.4f}")
            logger.info(f"    Validation Accuracy: {accuracy:.4f}")

            # Save best model
            if f1_macro > best_f1:
                best_f1 = f1_macro
                torch.save(model.state_dict(), "best_simple_model.pth")
                logger.info(f"    üíæ New best model saved! F1: {best_f1:.4f}")

        # Clear GPU cache
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    logger.info(f"üèÜ Training completed! Best F1 Score: {best_f1:.4f}")
    return best_f1


def main():
    """Main function with comprehensive error handling."""
    logger.info("üöÄ Starting bulletproof training for REQ-DL-012...")

    try:
        # Step 1: Validate environment
        if not validate_environment():
            logger.error("‚ùå Environment validation failed")
            return False

        # Step 2: Create unified label encoder
        label_encoder, label_to_id, id_to_label = create_unified_label_encoder()

        # Step 3: Prepare filtered data
        go_texts, go_labels, journal_texts, journal_labels = prepare_filtered_data(
            label_encoder, label_to_id
        )

        if go_texts is None:
            logger.error("‚ùå Data preparation failed")
            return False

        # Step 4: Train model
        num_labels = len(label_encoder.classes_)
        best_f1 = train_model_simple(
            go_texts, go_labels, journal_texts, journal_labels, num_labels
        )

        # Step 5: Save results
        results = {
            "best_f1": best_f1,
            "num_labels": num_labels,
            "target_achieved": best_f1 >= 0.7,
            "go_samples": len(go_texts),
            "journal_samples": len(journal_texts),
        }

        with open("simple_training_results.json", "w") as f:
            json.dump(results, f, indent=2)

        logger.info("‚úÖ Training completed successfully!")
        logger.info(f"üìä Final F1 Score: {best_f1:.4f}")
        logger.info(f"üéØ Target Met: {'‚úÖ' if best_f1 >= 0.7 else '‚ùå'}")

        return True

    except Exception as e:
        logger.error(f"‚ùå Training failed: {e}")
        return False


if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)
