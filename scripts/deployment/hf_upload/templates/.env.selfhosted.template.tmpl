# Self-Hosted Configuration
# Best for: Maximum control, custom requirements, data privacy

MODEL_NAME=$REPO_NAME
DEPLOYMENT_TYPE=local
DEVICE=cpu  # or 'cuda' if you have GPU

# Requires: pip install transformers torch

# Optional optimization settings
TORCH_NUM_THREADS=4
MODEL_CACHE_DIR=./model_cache
BATCH_SIZE=1
MAX_LENGTH=128
