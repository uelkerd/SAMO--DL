{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 MINIMAL WORKING EMOTION DETECTION TRAINING\n",
        "## Ultra-Simple Version That Should Work\n",
        "\n",
        "**FEATURES:**\n",
        "\u2705 Basic training (no complex arguments)\n",
        "\u2705 Configuration preservation\n",
        "\u2705 Simple data processing\n",
        "\u2705 Model saving with verification\n",
        "\n",
        "**Target**: Get training working first, then optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch scikit-learn numpy pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('\u2705 All packages imported successfully')\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd11 WANDB API KEY SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup Weights & Biases API key from Google Colab secrets\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "print('\ud83d\udd11 SETTING UP WANDB API KEY')\n",
        "print('=' * 40)\n",
        "\n",
        "# Try to get API key from Colab secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    \n",
        "    # Try different possible secret names\n",
        "    possible_secret_names = [\n",
        "        'WANDB_API_KEY',\n",
        "        'wandb_api_key',\n",
        "        'WANDB_KEY',\n",
        "        'wandb_key',\n",
        "        'WANDB_TOKEN',\n",
        "        'wandb_token'\n",
        "    ]\n",
        "    \n",
        "    api_key = None\n",
        "    used_secret_name = None\n",
        "    \n",
        "    for secret_name in possible_secret_names:\n",
        "        try:\n",
        "            api_key = userdata.get(secret_name)\n",
        "            used_secret_name = secret_name\n",
        "            print(f'\u2705 Found API key in secret: {secret_name}')\n",
        "            break\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    if api_key:\n",
        "        # Set the environment variable\n",
        "        os.environ['WANDB_API_KEY'] = api_key\n",
        "        print(f'\u2705 API key set from secret: {used_secret_name}')\n",
        "        \n",
        "        # Test wandb login\n",
        "        try:\n",
        "            wandb.login(key=api_key)\n",
        "            print('\u2705 WandB login successful!')\n",
        "        except Exception as e:\n",
        "            print(f'\u26a0\ufe0f WandB login failed: {str(e)}')\n",
        "            print('Continuing without WandB...')\n",
        "    else:\n",
        "        print('\u274c No WandB API key found in secrets')\n",
        "        print('\\n\ud83d\udccb TO SET UP WANDB SECRET:')\n",
        "        print('1. Go to Colab \u2192 Settings \u2192 Secrets')\n",
        "        print('2. Add a new secret with name: WANDB_API_KEY')\n",
        "        print('3. Value: Your WandB API key from https://wandb.ai/authorize')\n",
        "        print('4. Restart runtime and run this cell again')\n",
        "        print('\\n\u26a0\ufe0f Continuing without WandB logging...')\n",
        "        \n",
        "except ImportError:\n",
        "    print('\u26a0\ufe0f Google Colab secrets not available')\n",
        "    print('\\n\ud83d\udccb TO SET UP WANDB:')\n",
        "    print('1. Get your API key from: https://wandb.ai/authorize')\n",
        "    print('2. Run: wandb login')\n",
        "    print('3. Enter your API key when prompted')\n",
        "    print('\\n\u26a0\ufe0f Continuing without WandB logging...')\n",
        "\n",
        "print('\\n\u2705 WandB setup completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define emotion classes\n",
        "emotions = ['anxious', 'calm', 'content', 'excited', 'frustrated', 'grateful', 'happy', 'hopeful', 'overwhelmed', 'proud', 'sad', 'tired']\n",
        "print(f'\ud83c\udfaf Emotion classes: {emotions}')\n",
        "\n",
        "# Simple dataset\n",
        "data = [\n",
        "    {'text': 'I feel anxious about the presentation.', 'label': 0},\n",
        "    {'text': 'I am feeling calm today.', 'label': 1},\n",
        "    {'text': 'I feel content with my life.', 'label': 2},\n",
        "    {'text': 'I am excited about the opportunity.', 'label': 3},\n",
        "    {'text': 'I feel frustrated with the issues.', 'label': 4},\n",
        "    {'text': 'I am grateful for the support.', 'label': 5},\n",
        "    {'text': 'I feel happy about the success.', 'label': 6},\n",
        "    {'text': 'I am hopeful for the future.', 'label': 7},\n",
        "    {'text': 'I feel overwhelmed with tasks.', 'label': 8},\n",
        "    {'text': 'I am proud of my achievements.', 'label': 9},\n",
        "    {'text': 'I feel sad about the loss.', 'label': 10},\n",
        "    {'text': 'I am tired from working.', 'label': 11},\n",
        "    # Add more samples for each emotion\n",
        "    {'text': 'I am worried about the results.', 'label': 0},\n",
        "    {'text': 'I feel peaceful and relaxed.', 'label': 1},\n",
        "    {'text': 'I am satisfied with the outcome.', 'label': 2},\n",
        "    {'text': 'I feel thrilled about the news.', 'label': 3},\n",
        "    {'text': 'I am annoyed with the problems.', 'label': 4},\n",
        "    {'text': 'I feel thankful for the help.', 'label': 5},\n",
        "    {'text': 'I am joyful about the completion.', 'label': 6},\n",
        "    {'text': 'I feel optimistic about tomorrow.', 'label': 7},\n",
        "    {'text': 'I am stressed with responsibilities.', 'label': 8},\n",
        "    {'text': 'I feel accomplished and confident.', 'label': 9},\n",
        "    {'text': 'I am depressed about the situation.', 'label': 10},\n",
        "    {'text': 'I feel exhausted from the work.', 'label': 11}\n",
        "]\n",
        "\n",
        "print(f'\ud83d\udcca Dataset size: {len(data)} samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 MODEL SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model and tokenizer\n",
        "model_name = 'j-hartmann/emotion-english-distilroberta-base'\n",
        "print(f'\ud83d\udd27 Loading model: {model_name}')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(f'Original model labels: {AutoModelForSequenceClassification.from_pretrained(model_name).config.num_labels}')\n",
        "print(f'Original id2label: {AutoModelForSequenceClassification.from_pretrained(model_name).config.id2label}')\n",
        "\n",
        "# CRITICAL: Create a NEW model with correct configuration from scratch\n",
        "print('\\n\ud83d\udd27 CREATING NEW MODEL WITH CORRECT ARCHITECTURE')\n",
        "print('=' * 60)\n",
        "\n",
        "# Load the base model without the classification head\n",
        "from transformers import RobertaModel\n",
        "base_model = RobertaModel.from_pretrained(model_name)\n",
        "\n",
        "# Create a new model with the correct number of labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(emotions),  # Set to 12 emotions\n",
        "    ignore_mismatched_sizes=True  # Important: ignore size mismatches\n",
        ")\n",
        "\n",
        "# Configure the model properly\n",
        "model.config.num_labels = len(emotions)\n",
        "model.config.id2label = {i: emotion for i, emotion in enumerate(emotions)}\n",
        "model.config.label2id = {emotion: i for i, emotion in enumerate(emotions)}\n",
        "model.config.problem_type = 'single_label_classification'\n",
        "\n",
        "# Verify the configuration\n",
        "print(f'\u2705 Model created with {model.config.num_labels} labels')\n",
        "print(f'\u2705 New id2label: {model.config.id2label}')\n",
        "print(f'\u2705 Classifier output size: {model.classifier.out_proj.out_features}')\n",
        "print(f'\u2705 Problem type: {model.config.problem_type}')\n",
        "\n",
        "# Test the model with a sample input\n",
        "test_input = tokenizer('I feel happy today', return_tensors='pt', truncation=True, padding=True)\n",
        "with torch.no_grad():\n",
        "    test_output = model(**test_input)\n",
        "    print(f'\u2705 Test output shape: {test_output.logits.shape}')\n",
        "    print(f'\u2705 Expected shape: [1, {len(emotions)}]')\n",
        "    assert test_output.logits.shape[1] == len(emotions), f'Output shape mismatch: {test_output.logits.shape[1]} != {len(emotions)}'\n",
        "    print('\u2705 Model architecture verified!')\n",
        "\n",
        "# Move model to GPU\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to('cuda')\n",
        "    print('\u2705 Model moved to GPU')\n",
        "else:\n",
        "    print('\u26a0\ufe0f CUDA not available, model will run on CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcdd DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "texts = [item['text'] for item in data]\n",
        "labels = [item['label'] for item in data]\n",
        "\n",
        "# Split data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f'\ud83d\udcca Training samples: {len(train_texts)}')\n",
        "print(f'\ud83d\udcca Validation samples: {len(val_texts)}')\n",
        "\n",
        "# Tokenize\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "# Create dataset class\n",
        "class SimpleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SimpleDataset(train_encodings, train_labels)\n",
        "val_dataset = SimpleDataset(val_encodings, val_labels)\n",
        "\n",
        "print('\u2705 Data preprocessing completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2699\ufe0f MINIMAL TRAINING ARGUMENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Minimal training arguments - only essential parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./minimal_emotion_model',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    logging_steps=10,\n",
        "    save_steps=50,\n",
        "    eval_steps=50,\n",
        "    # Disable wandb if no API key is set\n",
        "    report_to=None if 'WANDB_API_KEY' not in os.environ else ['wandb']\n",
        ")\n",
        "\n",
        "print('\u2705 Minimal training arguments configured')\n",
        "if 'WANDB_API_KEY' in os.environ:\n",
        "    print('\u2705 WandB logging enabled')\n",
        "else:\n",
        "    print('\u26a0\ufe0f WandB logging disabled (no API key)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca COMPUTE METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple compute metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    return {\n",
        "        'f1': f1_score(labels, predictions, average='weighted'),\n",
        "        'accuracy': accuracy_score(labels, predictions)\n",
        "    }\n",
        "\n",
        "print('\u2705 Compute metrics function ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print('\u2705 Trainer initialized')\n",
        "\n",
        "# Start training\n",
        "print('\ud83d\ude80 STARTING MINIMAL TRAINING')\n",
        "print('=' * 40)\n",
        "print(f'\ud83d\udcca Training samples: {len(train_dataset)}')\n",
        "print(f'\ud83e\uddea Validation samples: {len(val_dataset)}')\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print('\u2705 Training completed successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc8 EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "print('\ud83d\udcc8 EVALUATING MODEL')\n",
        "print('=' * 40)\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print('\\n\ud83d\udcca FINAL RESULTS:')\n",
        "print(f'F1 Score: {results[\"eval_f1\"]:.4f}')\n",
        "print(f'Accuracy: {results[\"eval_accuracy\"]:.4f}')\n",
        "\n",
        "print('\u2705 Evaluation completed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcbe MODEL SAVING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "print('\ud83d\udcbe SAVING MODEL')\n",
        "print('=' * 30)\n",
        "\n",
        "model_path = './minimal_emotion_model_final'\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "print(f'\u2705 Model saved to: {model_path}')\n",
        "\n",
        "# Verify configuration\n",
        "config_path = f'{model_path}/config.json'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "print(f'\\n\ud83d\udd0d SAVED CONFIGURATION:')\n",
        "print(f'Model type: {config.get(\"model_type\", \"NOT SET\")}')\n",
        "print(f'Number of labels: {config.get(\"num_labels\", \"NOT SET\")}')\n",
        "print(f'id2label: {config.get(\"id2label\", \"NOT SET\")}')\n",
        "\n",
        "print('\\n\u2705 Model saving completed!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
