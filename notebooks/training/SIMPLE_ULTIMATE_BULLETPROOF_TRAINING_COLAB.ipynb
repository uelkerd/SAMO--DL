{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 SIMPLE ULTIMATE BULLETPROOF EMOTION DETECTION TRAINING\n",
        "## Avoiding Datasets Library Issues\n",
        "\n",
        "**FEATURES INCLUDED:**\n",
        "\u2705 Configuration preservation (prevents 8.3% vs 75% discrepancy)\n",
        "\u2705 Focal loss (handles class imbalance)\n",
        "\u2705 Class weighting (WeightedLossTrainer)\n",
        "\u2705 Data augmentation (sophisticated techniques)\n",
        "\u2705 Advanced validation (proper testing)\n",
        "\u2705 Simple, direct approach (no datasets library issues)\n",
        "\n",
        "**Target**: Reliable 75-85% F1 score with consistent performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch scikit-learn numpy pandas huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('\u2705 All packages imported successfully')\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd0d VERIFYING SPECIALIZED MODEL ACCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udd0d VERIFYING SPECIALIZED MODEL ACCESS')\n",
        "print('=' * 50)\n",
        "\n",
        "specialized_model_name = 'j-hartmann/emotion-english-distilroberta-base'\n",
        "\n",
        "try:\n",
        "    print(f'Testing access to: {specialized_model_name}')\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(specialized_model_name)\n",
        "    test_model = AutoModelForSequenceClassification.from_pretrained(specialized_model_name)\n",
        "    \n",
        "    print('\u2705 SUCCESS: Specialized model loaded!')\n",
        "    print(f'Model type: {test_model.config.model_type}')\n",
        "    print(f'Architecture: {test_model.config.architectures[0]}')\n",
        "    print(f'Hidden layers: {test_model.config.num_hidden_layers}')\n",
        "    print(f'Hidden size: {test_model.config.hidden_size}')\n",
        "    print(f'Number of labels: {test_model.config.num_labels}')\n",
        "    print(f'Original labels: {test_model.config.id2label}')\n",
        "    \n",
        "    # Verify it's actually DistilRoBERTa\n",
        "    if test_model.config.num_hidden_layers == 6:\n",
        "        print('\u2705 CONFIRMED: This is DistilRoBERTa architecture')\n",
        "    else:\n",
        "        print('\u26a0\ufe0f  WARNING: This may not be the expected DistilRoBERTa model')\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f'\u274c ERROR: Cannot access specialized model: {str(e)}')\n",
        "    print('\\n\ud83d\udd27 FALLBACK: Using roberta-base instead')\n",
        "    specialized_model_name = 'roberta-base'\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(specialized_model_name)\n",
        "    test_model = AutoModelForSequenceClassification.from_pretrained(specialized_model_name, num_labels=12)\n",
        "    print(f'\u2705 Fallback model loaded: {specialized_model_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf DEFINING EMOTION CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our emotion classes\n",
        "emotions = ['anxious', 'calm', 'content', 'excited', 'frustrated', 'grateful', 'happy', 'hopeful', 'overwhelmed', 'proud', 'sad', 'tired']\n",
        "print(f'\ud83c\udfaf Our emotion classes: {emotions}')\n",
        "print(f'\ud83d\udcca Number of emotions: {len(emotions)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca CREATING ENHANCED DATASET WITH AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udcca CREATING ENHANCED DATASET WITH AUGMENTATION')\n",
        "print('=' * 50)\n",
        "\n",
        "# Base balanced dataset\n",
        "base_data = [\n",
        "    # anxious (12 samples)\n",
        "    {'text': 'I feel anxious about the presentation.', 'label': 0},\n",
        "    {'text': 'I am anxious about the future.', 'label': 0},\n",
        "    {'text': 'This makes me feel anxious.', 'label': 0},\n",
        "    {'text': 'I am feeling anxious today.', 'label': 0},\n",
        "    {'text': 'The uncertainty makes me anxious.', 'label': 0},\n",
        "    {'text': 'I feel anxious about the results.', 'label': 0},\n",
        "    {'text': 'This situation is making me anxious.', 'label': 0},\n",
        "    {'text': 'I am anxious about the meeting.', 'label': 0},\n",
        "    {'text': 'The pressure is making me anxious.', 'label': 0},\n",
        "    {'text': 'I feel anxious about the decision.', 'label': 0},\n",
        "    {'text': 'This is causing me anxiety.', 'label': 0},\n",
        "    {'text': 'I am anxious about the changes.', 'label': 0},\n",
        "    \n",
        "    # calm (12 samples)\n",
        "    {'text': 'I feel calm and peaceful.', 'label': 1},\n",
        "    {'text': 'I am feeling calm today.', 'label': 1},\n",
        "    {'text': 'This makes me feel calm.', 'label': 1},\n",
        "    {'text': 'I am calm about the situation.', 'label': 1},\n",
        "    {'text': 'I feel calm and relaxed.', 'label': 1},\n",
        "    {'text': 'This gives me a sense of calm.', 'label': 1},\n",
        "    {'text': 'I am feeling calm and centered.', 'label': 1},\n",
        "    {'text': 'This brings me calm.', 'label': 1},\n",
        "    {'text': 'I feel calm and at peace.', 'label': 1},\n",
        "    {'text': 'I am calm about the outcome.', 'label': 1},\n",
        "    {'text': 'This creates a feeling of calm.', 'label': 1},\n",
        "    {'text': 'I feel calm and collected.', 'label': 1},\n",
        "    \n",
        "    # content (12 samples)\n",
        "    {'text': 'I feel content with my life.', 'label': 2},\n",
        "    {'text': 'I am content with the results.', 'label': 2},\n",
        "    {'text': 'This makes me feel content.', 'label': 2},\n",
        "    {'text': 'I am feeling content today.', 'label': 2},\n",
        "    {'text': 'I feel content and satisfied.', 'label': 2},\n",
        "    {'text': 'This gives me contentment.', 'label': 2},\n",
        "    {'text': 'I am content with my choices.', 'label': 2},\n",
        "    {'text': 'I feel content and fulfilled.', 'label': 2},\n",
        "    {'text': 'This brings me contentment.', 'label': 2},\n",
        "    {'text': 'I am content with the situation.', 'label': 2},\n",
        "    {'text': 'I feel content and at ease.', 'label': 2},\n",
        "    {'text': 'This creates contentment in me.', 'label': 2},\n",
        "    \n",
        "    # excited (12 samples)\n",
        "    {'text': 'I am excited about the new opportunity.', 'label': 3},\n",
        "    {'text': 'I feel excited about the future.', 'label': 3},\n",
        "    {'text': 'This makes me feel excited.', 'label': 3},\n",
        "    {'text': 'I am feeling excited today.', 'label': 3},\n",
        "    {'text': 'I feel excited and enthusiastic.', 'label': 3},\n",
        "    {'text': 'This gives me excitement.', 'label': 3},\n",
        "    {'text': 'I am excited about the project.', 'label': 3},\n",
        "    {'text': 'I feel excited and motivated.', 'label': 3},\n",
        "    {'text': 'This brings me excitement.', 'label': 3},\n",
        "    {'text': 'I am excited about the possibilities.', 'label': 3},\n",
        "    {'text': 'I feel excited and energized.', 'label': 3},\n",
        "    {'text': 'This creates excitement in me.', 'label': 3},\n",
        "    \n",
        "    # frustrated (12 samples)\n",
        "    {'text': 'I am so frustrated with this project.', 'label': 4},\n",
        "    {'text': 'I feel frustrated about the situation.', 'label': 4},\n",
        "    {'text': 'This makes me feel frustrated.', 'label': 4},\n",
        "    {'text': 'I am feeling frustrated today.', 'label': 4},\n",
        "    {'text': 'I feel frustrated and annoyed.', 'label': 4},\n",
        "    {'text': 'This gives me frustration.', 'label': 4},\n",
        "    {'text': 'I am frustrated with the results.', 'label': 4},\n",
        "    {'text': 'I feel frustrated and irritated.', 'label': 4},\n",
        "    {'text': 'This brings me frustration.', 'label': 4},\n",
        "    {'text': 'I am frustrated with the process.', 'label': 4},\n",
        "    {'text': 'I feel frustrated and upset.', 'label': 4},\n",
        "    {'text': 'This creates frustration in me.', 'label': 4},\n",
        "    \n",
        "    # grateful (12 samples)\n",
        "    {'text': 'I am grateful for all the support.', 'label': 5},\n",
        "    {'text': 'I feel grateful for the opportunity.', 'label': 5},\n",
        "    {'text': 'This makes me feel grateful.', 'label': 5},\n",
        "    {'text': 'I am feeling grateful today.', 'label': 5},\n",
        "    {'text': 'I feel grateful and thankful.', 'label': 5},\n",
        "    {'text': 'This gives me gratitude.', 'label': 5},\n",
        "    {'text': 'I am grateful for the help.', 'label': 5},\n",
        "    {'text': 'I feel grateful and appreciative.', 'label': 5},\n",
        "    {'text': 'This brings me gratitude.', 'label': 5},\n",
        "    {'text': 'I am grateful for the kindness.', 'label': 5},\n",
        "    {'text': 'I feel grateful and blessed.', 'label': 5},\n",
        "    {'text': 'This creates gratitude in me.', 'label': 5},\n",
        "    \n",
        "    # happy (12 samples)\n",
        "    {'text': 'I am feeling really happy today!', 'label': 6},\n",
        "    {'text': 'I feel happy about the news.', 'label': 6},\n",
        "    {'text': 'This makes me feel happy.', 'label': 6},\n",
        "    {'text': 'I am feeling happy today.', 'label': 6},\n",
        "    {'text': 'I feel happy and joyful.', 'label': 6},\n",
        "    {'text': 'This gives me happiness.', 'label': 6},\n",
        "    {'text': 'I am happy with the results.', 'label': 6},\n",
        "    {'text': 'I feel happy and delighted.', 'label': 6},\n",
        "    {'text': 'This brings me happiness.', 'label': 6},\n",
        "    {'text': 'I am happy about the success.', 'label': 6},\n",
        "    {'text': 'I feel happy and cheerful.', 'label': 6},\n",
        "    {'text': 'This creates happiness in me.', 'label': 6},\n",
        "    \n",
        "    # hopeful (12 samples)\n",
        "    {'text': 'I am hopeful for the future.', 'label': 7},\n",
        "    {'text': 'I feel hopeful about the outcome.', 'label': 7},\n",
        "    {'text': 'This makes me feel hopeful.', 'label': 7},\n",
        "    {'text': 'I am feeling hopeful today.', 'label': 7},\n",
        "    {'text': 'I feel hopeful and optimistic.', 'label': 7},\n",
        "    {'text': 'This gives me hope.', 'label': 7},\n",
        "    {'text': 'I am hopeful about the changes.', 'label': 7},\n",
        "    {'text': 'I feel hopeful and positive.', 'label': 7},\n",
        "    {'text': 'This brings me hope.', 'label': 7},\n",
        "    {'text': 'I am hopeful about the possibilities.', 'label': 7},\n",
        "    {'text': 'I feel hopeful and confident.', 'label': 7},\n",
        "    {'text': 'This creates hope in me.', 'label': 7},\n",
        "    \n",
        "    # overwhelmed (12 samples)\n",
        "    {'text': 'I am feeling overwhelmed with tasks.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed by the workload.', 'label': 8},\n",
        "    {'text': 'This makes me feel overwhelmed.', 'label': 8},\n",
        "    {'text': 'I am feeling overwhelmed today.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed and stressed.', 'label': 8},\n",
        "    {'text': 'This gives me overwhelm.', 'label': 8},\n",
        "    {'text': 'I am overwhelmed with responsibilities.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed and exhausted.', 'label': 8},\n",
        "    {'text': 'This brings me overwhelm.', 'label': 8},\n",
        "    {'text': 'I am overwhelmed with the pressure.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed and drained.', 'label': 8},\n",
        "    {'text': 'This creates overwhelm in me.', 'label': 8},\n",
        "    \n",
        "    # proud (12 samples)\n",
        "    {'text': 'I am proud of my accomplishments.', 'label': 9},\n",
        "    {'text': 'I feel proud of the results.', 'label': 9},\n",
        "    {'text': 'This makes me feel proud.', 'label': 9},\n",
        "    {'text': 'I am feeling proud today.', 'label': 9},\n",
        "    {'text': 'I feel proud and accomplished.', 'label': 9},\n",
        "    {'text': 'This gives me pride.', 'label': 9},\n",
        "    {'text': 'I am proud of my achievements.', 'label': 9},\n",
        "    {'text': 'I feel proud and satisfied.', 'label': 9},\n",
        "    {'text': 'This brings me pride.', 'label': 9},\n",
        "    {'text': 'I am proud of my progress.', 'label': 9},\n",
        "    {'text': 'I feel proud and confident.', 'label': 9},\n",
        "    {'text': 'This creates pride in me.', 'label': 9},\n",
        "    \n",
        "    # sad (12 samples)\n",
        "    {'text': 'I feel sad about the loss.', 'label': 10},\n",
        "    {'text': 'I am sad about the situation.', 'label': 10},\n",
        "    {'text': 'This makes me feel sad.', 'label': 10},\n",
        "    {'text': 'I am feeling sad today.', 'label': 10},\n",
        "    {'text': 'I feel sad and down.', 'label': 10},\n",
        "    {'text': 'This gives me sadness.', 'label': 10},\n",
        "    {'text': 'I am sad about the outcome.', 'label': 10},\n",
        "    {'text': 'I feel sad and depressed.', 'label': 10},\n",
        "    {'text': 'This brings me sadness.', 'label': 10},\n",
        "    {'text': 'I am sad about the news.', 'label': 10},\n",
        "    {'text': 'I feel sad and heartbroken.', 'label': 10},\n",
        "    {'text': 'This creates sadness in me.', 'label': 10},\n",
        "    \n",
        "    # tired (12 samples)\n",
        "    {'text': 'I am tired from working all day.', 'label': 11},\n",
        "    {'text': 'I feel tired of the routine.', 'label': 11},\n",
        "    {'text': 'This makes me feel tired.', 'label': 11},\n",
        "    {'text': 'I am feeling tired today.', 'label': 11},\n",
        "    {'text': 'I feel tired and exhausted.', 'label': 11},\n",
        "    {'text': 'This gives me fatigue.', 'label': 11},\n",
        "    {'text': 'I am tired of the stress.', 'label': 11},\n",
        "    {'text': 'I feel tired and worn out.', 'label': 11},\n",
        "    {'text': 'This brings me fatigue.', 'label': 11},\n",
        "    {'text': 'I am tired of the pressure.', 'label': 11},\n",
        "    {'text': 'I feel tired and drained.', 'label': 11},\n",
        "    {'text': 'This creates fatigue in me.', 'label': 11}\n",
        "]\n",
        "\n",
        "print(f'\ud83d\udcca Base dataset size: {len(base_data)} samples')\n",
        "\n",
        "# Data augmentation function\n",
        "def augment_text(text, emotion):\n",
        "    \"\"\"Create augmented versions of the text.\"\"\"\n",
        "    augmented = []\n",
        "    \n",
        "    # Synonym replacement\n",
        "    synonyms = {\n",
        "        'anxious': ['worried', 'nervous', 'concerned', 'uneasy'],\n",
        "        'calm': ['peaceful', 'serene', 'tranquil', 'relaxed'],\n",
        "        'content': ['satisfied', 'fulfilled', 'pleased', 'happy'],\n",
        "        'excited': ['thrilled', 'enthusiastic', 'eager', 'pumped'],\n",
        "        'frustrated': ['annoyed', 'irritated', 'aggravated', 'bothered'],\n",
        "        'grateful': ['thankful', 'appreciative', 'blessed', 'indebted'],\n",
        "        'happy': ['joyful', 'cheerful', 'delighted', 'pleased'],\n",
        "        'hopeful': ['optimistic', 'positive', 'confident', 'assured'],\n",
        "        'overwhelmed': ['stressed', 'burdened', 'swamped', 'flooded'],\n",
        "        'proud': ['accomplished', 'satisfied', 'confident', 'pleased'],\n",
        "        'sad': ['down', 'depressed', 'melancholy', 'blue'],\n",
        "        'tired': ['exhausted', 'fatigued', 'weary', 'drained']\n",
        "    }\n",
        "    \n",
        "    # Create variations with synonyms\n",
        "    for synonym in synonyms.get(emotion, [emotion])[:2]:  # Use first 2 synonyms\n",
        "        new_text = text.replace(emotion, synonym)\n",
        "        if new_text != text:\n",
        "            augmented.append({'text': new_text, 'label': emotions.index(emotion)})\n",
        "    \n",
        "    # Add intensity variations\n",
        "    intensity_words = ['really', 'very', 'extremely', 'quite', 'somewhat']\n",
        "    for intensity in intensity_words[:2]:\n",
        "        if intensity not in text.lower():\n",
        "            new_text = f'I am {intensity} {emotion}.'\n",
        "            augmented.append({'text': new_text, 'label': emotions.index(emotion)})\n",
        "    \n",
        "    return augmented\n",
        "\n",
        "# Apply augmentation\n",
        "augmented_data = []\n",
        "for item in base_data:\n",
        "    emotion = emotions[item['label']]\n",
        "    augmented = augment_text(item['text'], emotion)\n",
        "    augmented_data.extend(augmented)\n",
        "\n",
        "# Combine base and augmented data\n",
        "enhanced_data = base_data + augmented_data\n",
        "print(f'\ud83d\udcca Enhanced dataset size: {len(enhanced_data)} samples')\n",
        "print(f'\ud83d\udcca Augmentation added: {len(augmented_data)} samples')\n",
        "\n",
        "# Convert to lists for simple processing\n",
        "texts = [item['text'] for item in enhanced_data]\n",
        "labels = [item['label'] for item in enhanced_data]\n",
        "\n",
        "print(f'\u2705 Dataset prepared with {len(texts)} samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf FOCAL LOSS IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Focal Loss Implementation\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    \"\"\"Focal Loss for handling class imbalance.\"\"\"\n",
        "    \n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    \n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = torch.nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        \n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "print('\u2705 Focal Loss implementation ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2696\ufe0f CLASS WEIGHTING & WEIGHTED LOSS TRAINER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate class weights\n",
        "print('\u2696\ufe0f CALCULATING CLASS WEIGHTS')\n",
        "print('=' * 40)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "\n",
        "class_weights_tensor = torch.FloatTensor(class_weights)\n",
        "if torch.cuda.is_available():\n",
        "    class_weights_tensor = class_weights_tensor.cuda()\n",
        "\n",
        "print(f'Class weights: {class_weights}')\n",
        "print(f'Class weights tensor shape: {class_weights_tensor.shape}')\n",
        "print('\u2705 Class weights calculated')\n",
        "\n",
        "# Weighted Loss Trainer\n",
        "class WeightedLossTrainer(Trainer):\n",
        "    \"\"\"Custom trainer with focal loss and class weighting.\"\"\"\n",
        "    \n",
        "    def __init__(self, focal_alpha=1, focal_gamma=2, class_weights=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)\n",
        "        self.class_weights = class_weights\n",
        "    \n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        \n",
        "        # Apply focal loss with class weighting\n",
        "        if self.class_weights is not None:\n",
        "            # Apply class weights to focal loss\n",
        "            ce_loss = torch.nn.functional.cross_entropy(logits, labels, reduction='none')\n",
        "            pt = torch.exp(-ce_loss)\n",
        "            focal_loss = (1 - pt) ** self.focal_loss.gamma * ce_loss\n",
        "            \n",
        "            # Apply class weights\n",
        "            for i, weight in enumerate(self.class_weights):\n",
        "                mask = (labels == i)\n",
        "                focal_loss[mask] *= weight\n",
        "            \n",
        "            loss = focal_loss.mean()\n",
        "        else:\n",
        "            loss = self.focal_loss(logits, labels)\n",
        "        \n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "print('\u2705 WeightedLossTrainer ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 LOADING & CONFIGURING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tokenizer and model\n",
        "print('\ud83d\udd27 LOADING & CONFIGURING MODEL')\n",
        "print('=' * 40)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(specialized_model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(specialized_model_name)\n",
        "\n",
        "# Configure model for our emotion classes\n",
        "model.config.num_labels = len(emotions)\n",
        "model.config.id2label = {i: emotion for i, emotion in enumerate(emotions)}\n",
        "model.config.label2id = {emotion: i for i, emotion in enumerate(emotions)}\n",
        "\n",
        "# Verify configuration\n",
        "print(f'\u2705 Model configured for {len(emotions)} emotions')\n",
        "print(f'\u2705 id2label: {model.config.id2label}')\n",
        "print(f'\u2705 label2id: {model.config.label2id}')\n",
        "\n",
        "# Move to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "print(f'\u2705 Model moved to: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcdd DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple preprocessing without datasets library\n",
        "print('\ud83d\udcdd PREPROCESSING DATA')\n",
        "print('=' * 40)\n",
        "\n",
        "# Split data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f'\ud83d\udcca Training samples: {len(train_texts)}')\n",
        "print(f'\ud83d\udcca Validation samples: {len(val_texts)}')\n",
        "\n",
        "# Tokenize training data\n",
        "train_encodings = tokenizer(\n",
        "    train_texts,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=128,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Tokenize validation data\n",
        "val_encodings = tokenizer(\n",
        "    val_texts,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=128,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Create simple dataset class\n",
        "class SimpleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SimpleDataset(train_encodings, train_labels)\n",
        "val_dataset = SimpleDataset(val_encodings, val_labels)\n",
        "\n",
        "print('\u2705 Data preprocessing completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2699\ufe0f TRAINING ARGUMENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./ultimate_emotion_model',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        "    greater_is_better=True,\n",
        "    report_to='wandb',\n",
        "    run_name='ultimate_emotion_model'\n",
        ")\n",
        "\n",
        "print('\u2705 Training arguments configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca COMPUTE METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute evaluation metrics.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    return {\n",
        "        'f1': f1_score(labels, predictions, average='weighted'),\n",
        "        'accuracy': accuracy_score(labels, predictions),\n",
        "        'precision': precision_score(labels, predictions, average='weighted'),\n",
        "        'recall': recall_score(labels, predictions, average='weighted')\n",
        "    }\n",
        "\n",
        "print('\u2705 Compute metrics function ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = WeightedLossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    focal_alpha=1,\n",
        "    focal_gamma=2,\n",
        "    class_weights=class_weights_tensor\n",
        ")\n",
        "\n",
        "print('\u2705 Trainer initialized with focal loss and class weighting')\n",
        "\n",
        "# Start training\n",
        "print('\ud83d\ude80 STARTING ULTIMATE TRAINING')\n",
        "print('=' * 50)\n",
        "print(f'\ud83c\udfaf Target: 75-85% F1 score')\n",
        "print(f'\ud83d\udcca Training samples: {len(train_dataset)}')\n",
        "print(f'\ud83e\uddea Validation samples: {len(val_dataset)}')\n",
        "print(f'\u2696\ufe0f Using focal loss + class weighting')\n",
        "print(f'\ud83d\udd27 Model: {specialized_model_name}')\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print('\u2705 Training completed successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc8 EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "print('\ud83d\udcc8 EVALUATING MODEL')\n",
        "print('=' * 40)\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print('\\n\ud83d\udcca FINAL RESULTS:')\n",
        "print(f'F1 Score: {results[\"eval_f1\"]:.4f}')\n",
        "print(f'Accuracy: {results[\"eval_accuracy\"]:.4f}')\n",
        "print(f'Precision: {results[\"eval_precision\"]:.4f}')\n",
        "print(f'Recall: {results[\"eval_recall\"]:.4f}')\n",
        "\n",
        "print('\u2705 Evaluation completed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\uddea ADVANCED VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced validation on diverse examples\n",
        "print('\ud83e\uddea ADVANCED VALIDATION')\n",
        "print('=' * 40)\n",
        "\n",
        "# Test examples\n",
        "test_examples = [\n",
        "    'I am feeling anxious about the presentation tomorrow.',\n",
        "    'I feel calm and peaceful after meditation.',\n",
        "    'I am excited about the new job opportunity!',\n",
        "    'I feel frustrated with the technical issues.',\n",
        "    'I am grateful for all the support I received.',\n",
        "    'I feel happy about the successful completion.',\n",
        "    'I am hopeful for a better future.',\n",
        "    'I feel overwhelmed with all the responsibilities.',\n",
        "    'I am proud of my achievements.',\n",
        "    'I feel sad about the recent loss.',\n",
        "    'I am tired from working long hours.',\n",
        "    'I feel content with my current situation.'\n",
        "]\n",
        "\n",
        "print('\ud83d\udd0d Testing on diverse examples:')\n",
        "for i, example in enumerate(test_examples):\n",
        "    inputs = tokenizer(example, return_tensors='pt', truncation=True, padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "        confidence = predictions[0][predicted_class].item()\n",
        "    \n",
        "    print(f'{i+1:2d}. \"{example}\" \u2192 {emotions[predicted_class]} ({confidence:.3f})')\n",
        "\n",
        "print('\u2705 Advanced validation completed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcbe MODEL SAVING WITH VERIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model with verification\n",
        "print('\ud83d\udcbe SAVING MODEL WITH VERIFICATION')\n",
        "print('=' * 50)\n",
        "\n",
        "# Save the model\n",
        "model_path = './ultimate_emotion_model_final'\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "print(f'\u2705 Model saved to: {model_path}')\n",
        "\n",
        "# Verify the saved configuration\n",
        "print('\\n\ud83d\udd0d VERIFYING SAVED CONFIGURATION:')\n",
        "config_path = f'{model_path}/config.json'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "print(f'Model type: {config.get(\"model_type\", \"NOT SET\")}')\n",
        "print(f'Number of labels: {config.get(\"num_labels\", \"NOT SET\")}')\n",
        "print(f'id2label: {config.get(\"id2label\", \"NOT SET\")}')\n",
        "print(f'label2id: {config.get(\"label2id\", \"NOT SET\")}')\n",
        "\n",
        "# Test loading the saved model\n",
        "print('\\n\ud83e\uddea TESTING SAVED MODEL:')\n",
        "test_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "test_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "test_input = 'I feel happy about the results!'\n",
        "test_encoding = test_tokenizer(test_input, return_tensors='pt', truncation=True, padding=True)\n",
        "test_encoding = {k: v.to(device) for k, v in test_encoding.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_outputs = test_model(**test_encoding)\n",
        "    test_predictions = torch.nn.functional.softmax(test_outputs.logits, dim=-1)\n",
        "    test_predicted_class = torch.argmax(test_predictions, dim=-1).item()\n",
        "    test_confidence = test_predictions[0][test_predicted_class].item()\n",
        "\n",
        "print(f'Test input: \"{test_input}\"')\n",
        "print(f'Predicted emotion: {test_model.config.id2label[test_predicted_class]}')\n",
        "print(f'Confidence: {test_confidence:.3f}')\n",
        "\n",
        "print('\\n\u2705 Model saving and verification completed!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
