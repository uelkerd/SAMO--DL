{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# \ud83d\ude80 REQ-DL-012: Expanded Dataset Retraining\n",
        "## Domain-Adapted Emotion Detection with 1000+ Samples\n",
        "\n",
        "**Target**: Achieve 75-85% F1 Score\n",
        "**Current**: 67% F1 Score\n",
        "**Expected Improvement**: 8-18% F1 Score\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## \ud83d\udd27 Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/uelkerd/SAMO--DL.git\n",
        "%cd SAMO--DL\n",
        "print(\"\u2705 Repository cloned and ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies with compatibility fixes\n",
        "print(\"\ud83d\udce6 Installing dependencies with compatibility fixes...\")\n",
        "\n",
        "# Step 1: Uninstall existing PyTorch to avoid conflicts\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "\n",
        "# Step 2: Install PyTorch with compatible CUDA version\n",
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Step 3: Install Transformers with compatible version\n",
        "!pip install transformers==4.30.0 datasets==2.13.0 evaluate scikit-learn pandas numpy matplotlib seaborn\n",
        "\n",
        "# Step 4: Verify installation\n",
        "print(\"\ud83d\udd0d Verifying installation...\")\n",
        "import torch\n",
        "import transformers\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Transformers: {transformers.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Step 5: Test critical imports\n",
        "try:\n",
        "    from transformers import AutoModel, AutoTokenizer\n",
        "    print(\"\u2705 Transformers imports successful\")\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Transformers import failed: {e}\")\n",
        "    print(\"\ud83d\udd04 Restarting runtime and trying again...\")\n",
        "    import os\n",
        "    os._exit(0)  # Force restart\n",
        "\n",
        "print(\"\u2705 Dependencies installed and verified!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expand_dataset"
      },
      "source": [
        "## \ud83d\udcca Create Expanded Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_expanded_dataset"
      },
      "outputs": [],
      "source": [
        "# Create expanded dataset directly in Colab\n",
        "import json\n",
        "import random\n",
        "from typing import List, Dict\n",
        "\n",
        "def load_current_dataset():\n",
        "    \"\"\"Load the current journal dataset.\"\"\"\n",
        "    with open('data/journal_test_dataset.json', 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def create_variation(base_sample: Dict, emotion: str) -> Dict:\n",
        "    \"\"\"Create a variation of a base sample.\"\"\"\n",
        "    \n",
        "    # Templates for different emotions\n",
        "    emotion_templates = {\n",
        "        'happy': [\n",
        "            \"I'm feeling really happy today!\",\n",
        "            \"I'm so happy about this!\",\n",
        "            \"This makes me incredibly happy!\",\n",
        "            \"I'm feeling joyful and happy!\",\n",
        "            \"I'm really happy with how things are going!\",\n",
        "            \"This brings me so much happiness!\",\n",
        "            \"I'm feeling happy and content!\",\n",
        "            \"I'm really happy about this outcome!\",\n",
        "            \"This makes me feel so happy!\",\n",
        "            \"I'm feeling happy and grateful!\"\n",
        "        ],\n",
        "        'sad': [\n",
        "            \"I'm feeling really sad today.\",\n",
        "            \"This makes me so sad.\",\n",
        "            \"I'm feeling down and sad.\",\n",
        "            \"I'm really sad about this situation.\",\n",
        "            \"This brings me sadness.\",\n",
        "            \"I'm feeling sad and lonely.\",\n",
        "            \"I'm really sad about what happened.\",\n",
        "            \"This makes me feel so sad.\",\n",
        "            \"I'm feeling sad and disappointed.\",\n",
        "            \"I'm really sad about this outcome.\"\n",
        "        ],\n",
        "        'frustrated': [\n",
        "            \"I'm so frustrated with this!\",\n",
        "            \"This is really frustrating me.\",\n",
        "            \"I'm feeling frustrated and annoyed.\",\n",
        "            \"I'm really frustrated about this situation.\",\n",
        "            \"This is so frustrating!\",\n",
        "            \"I'm feeling frustrated and angry.\",\n",
        "            \"I'm really frustrated with how this is going.\",\n",
        "            \"This makes me so frustrated.\",\n",
        "            \"I'm feeling frustrated and upset.\",\n",
        "            \"I'm really frustrated about this outcome.\"\n",
        "        ],\n",
        "        'anxious': [\n",
        "            \"I'm feeling really anxious about this.\",\n",
        "            \"This is making me anxious.\",\n",
        "            \"I'm feeling anxious and worried.\",\n",
        "            \"I'm really anxious about what might happen.\",\n",
        "            \"This gives me anxiety.\",\n",
        "            \"I'm feeling anxious and nervous.\",\n",
        "            \"I'm really anxious about this situation.\",\n",
        "            \"This makes me feel so anxious.\",\n",
        "            \"I'm feeling anxious and stressed.\",\n",
        "            \"I'm really anxious about the outcome.\"\n",
        "        ],\n",
        "        'excited': [\n",
        "            \"I'm so excited about this!\",\n",
        "            \"This makes me really excited!\",\n",
        "            \"I'm feeling excited and enthusiastic!\",\n",
        "            \"I'm really excited about what's coming!\",\n",
        "            \"This is so exciting!\",\n",
        "            \"I'm feeling excited and eager!\",\n",
        "            \"I'm really excited about this opportunity!\",\n",
        "            \"This makes me feel so excited!\",\n",
        "            \"I'm feeling excited and thrilled!\",\n",
        "            \"I'm really excited about this outcome!\"\n",
        "        ],\n",
        "        'calm': [\n",
        "            \"I'm feeling really calm right now.\",\n",
        "            \"This brings me a sense of calm.\",\n",
        "            \"I'm feeling calm and peaceful.\",\n",
        "            \"I'm really calm about this situation.\",\n",
        "            \"This makes me feel calm.\",\n",
        "            \"I'm feeling calm and relaxed.\",\n",
        "            \"I'm really calm about what's happening.\",\n",
        "            \"This gives me a calm feeling.\",\n",
        "            \"I'm feeling calm and content.\",\n",
        "            \"I'm really calm about this outcome.\"\n",
        "        ],\n",
        "        'content': [\n",
        "            \"I'm feeling really content with this.\",\n",
        "            \"This makes me feel content.\",\n",
        "            \"I'm feeling content and satisfied.\",\n",
        "            \"I'm really content with how things are.\",\n",
        "            \"This brings me contentment.\",\n",
        "            \"I'm feeling content and happy.\",\n",
        "            \"I'm really content with this situation.\",\n",
        "            \"This makes me feel so content.\",\n",
        "            \"I'm feeling content and peaceful.\",\n",
        "            \"I'm really content with this outcome.\"\n",
        "        ],\n",
        "        'grateful': [\n",
        "            \"I'm feeling really grateful for this.\",\n",
        "            \"This makes me so grateful.\",\n",
        "            \"I'm feeling grateful and thankful.\",\n",
        "            \"I'm really grateful for this opportunity.\",\n",
        "            \"This fills me with gratitude.\",\n",
        "            \"I'm feeling grateful and blessed.\",\n",
        "            \"I'm really grateful for this situation.\",\n",
        "            \"This makes me feel so grateful.\",\n",
        "            \"I'm feeling grateful and appreciative.\",\n",
        "            \"I'm really grateful for this outcome.\"\n",
        "        ],\n",
        "        'hopeful': [\n",
        "            \"I'm feeling really hopeful about this.\",\n",
        "            \"This gives me hope.\",\n",
        "            \"I'm feeling hopeful and optimistic.\",\n",
        "            \"I'm really hopeful about what's coming.\",\n",
        "            \"This brings me hope.\",\n",
        "            \"I'm feeling hopeful and positive.\",\n",
        "            \"I'm really hopeful about this situation.\",\n",
        "            \"This makes me feel so hopeful.\",\n",
        "            \"I'm feeling hopeful and confident.\",\n",
        "            \"I'm really hopeful about this outcome.\"\n",
        "        ],\n",
        "        'overwhelmed': [\n",
        "            \"I'm feeling really overwhelmed by this.\",\n",
        "            \"This is overwhelming me.\",\n",
        "            \"I'm feeling overwhelmed and stressed.\",\n",
        "            \"I'm really overwhelmed by this situation.\",\n",
        "            \"This is so overwhelming.\",\n",
        "            \"I'm feeling overwhelmed and anxious.\",\n",
        "            \"I'm really overwhelmed by what's happening.\",\n",
        "            \"This makes me feel so overwhelmed.\",\n",
        "            \"I'm feeling overwhelmed and exhausted.\",\n",
        "            \"I'm really overwhelmed by this outcome.\"\n",
        "        ],\n",
        "        'proud': [\n",
        "            \"I'm feeling really proud of this.\",\n",
        "            \"This makes me so proud.\",\n",
        "            \"I'm feeling proud and accomplished.\",\n",
        "            \"I'm really proud of what I've done.\",\n",
        "            \"This fills me with pride.\",\n",
        "            \"I'm feeling proud and satisfied.\",\n",
        "            \"I'm really proud of this achievement.\",\n",
        "            \"This makes me feel so proud.\",\n",
        "            \"I'm feeling proud and confident.\",\n",
        "            \"I'm really proud of this outcome.\"\n",
        "        ],\n",
        "        'tired': [\n",
        "            \"I'm feeling really tired today.\",\n",
        "            \"This is making me tired.\",\n",
        "            \"I'm feeling tired and exhausted.\",\n",
        "            \"I'm really tired from all this work.\",\n",
        "            \"This is so tiring.\",\n",
        "            \"I'm feeling tired and worn out.\",\n",
        "            \"I'm really tired of this situation.\",\n",
        "            \"This makes me feel so tired.\",\n",
        "            \"I'm feeling tired and drained.\",\n",
        "            \"I'm really tired of dealing with this.\"\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Get templates for this emotion\n",
        "    templates = emotion_templates.get(emotion, [f\"I'm feeling {emotion}.\"])\n",
        "    \n",
        "    # Create variation\n",
        "    template = random.choice(templates)\n",
        "    \n",
        "    # Add some variety to the content\n",
        "    variations = [\n",
        "        f\"{template} {random.choice(['It\\'s been a long day.', 'Things are going well.', 'I need to process this.', 'This is important to me.'])}\",\n",
        "        f\"{template} {random.choice(['I hope this continues.', 'I wonder what\\'s next.', 'This feels right.', 'I\\'m processing this.'])}\",\n",
        "        f\"{template} {random.choice(['I should reflect on this.', 'This is meaningful.', 'I appreciate this moment.', 'I\\'m learning from this.'])}\"\n",
        "    ]\n",
        "    \n",
        "    content = random.choice(variations)\n",
        "    \n",
        "    return {\n",
        "        'content': content,\n",
        "        'emotion': emotion,\n",
        "        'id': f\"expanded_{emotion}_{random.randint(1000, 9999)}\"\n",
        "    }\n",
        "\n",
        "def create_balanced_dataset(target_size=1000):\n",
        "    \"\"\"Create a balanced expanded dataset.\"\"\"\n",
        "    print(\"\ud83d\udd27 Creating balanced expanded dataset...\")\n",
        "    \n",
        "    # Load current data\n",
        "    current_data = load_current_dataset()\n",
        "    \n",
        "    # Analyze current distribution\n",
        "    emotion_counts = {}\n",
        "    for entry in current_data:\n",
        "        emotion = entry['emotion']\n",
        "        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
        "    \n",
        "    print(f\"\ud83d\udcca Current emotion distribution:\")\n",
        "    for emotion, count in sorted(emotion_counts.items()):\n",
        "        print(f\"  {emotion}: {count} samples\")\n",
        "    \n",
        "    # Calculate target per emotion\n",
        "    target_per_emotion = target_size // len(emotion_counts)\n",
        "    print(f\"\\n\ud83c\udfaf Target: {target_per_emotion} samples per emotion\")\n",
        "    \n",
        "    # Create expanded dataset\n",
        "    expanded_data = []\n",
        "    \n",
        "    for emotion in emotion_counts.keys():\n",
        "        # Get existing samples for this emotion\n",
        "        existing_samples = [entry for entry in current_data if entry['emotion'] == emotion]\n",
        "        current_count = len(existing_samples)\n",
        "        \n",
        "        print(f\"\\n\ud83d\udcdd Expanding '{emotion}' from {current_count} to {target_per_emotion} samples...\")\n",
        "        \n",
        "        # Add existing samples\n",
        "        expanded_data.extend(existing_samples)\n",
        "        \n",
        "        # Generate additional samples\n",
        "        needed_samples = target_per_emotion - current_count\n",
        "        \n",
        "        if needed_samples > 0:\n",
        "            # Create variations of existing samples\n",
        "            for i in range(needed_samples):\n",
        "                # Pick a random existing sample to base variation on\n",
        "                base_sample = random.choice(existing_samples)\n",
        "                \n",
        "                # Create variation\n",
        "                variation = create_variation(base_sample, emotion)\n",
        "                expanded_data.append(variation)\n",
        "    \n",
        "    print(f\"\\n\u2705 Expanded dataset created:\")\n",
        "    print(f\"  Original samples: {len(current_data)}\")\n",
        "    print(f\"  Expanded samples: {len(expanded_data)}\")\n",
        "    print(f\"  Target size: {target_size}\")\n",
        "    \n",
        "    return expanded_data\n",
        "\n",
        "# Create expanded dataset\n",
        "expanded_data = create_balanced_dataset(target_size=1000)\n",
        "\n",
        "# Save expanded dataset\n",
        "with open('data/expanded_journal_dataset.json', 'w') as f:\n",
        "    json.dump(expanded_data, f, indent=2)\n",
        "\n",
        "print(\"\u2705 Expanded dataset saved to data/expanded_journal_dataset.json\")\n",
        "\n",
        "# Analyze expanded dataset\n",
        "emotion_counts = {}\n",
        "for entry in expanded_data:\n",
        "    emotion = entry['emotion']\n",
        "    emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
        "\n",
        "print(\"\\n\ud83d\udcca Expanded Dataset Analysis:\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Emotion distribution:\")\n",
        "for emotion, count in sorted(emotion_counts.items()):\n",
        "    print(f\"  {emotion}: {count} samples\")\n",
        "\n",
        "print(f\"\\nTotal samples: {len(expanded_data)}\")\n",
        "print(f\"Unique emotions: {len(emotion_counts)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training"
      },
      "source": [
        "## \ud83d\ude80 Training with Expanded Dataset (GPU Optimized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "expanded_training"
      },
      "outputs": [],
      "source": [
        "# Complete training script with expanded dataset and GPU optimizations\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import numpy as np\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "class ExpandedEmotionDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class ExpandedEmotionClassifier(nn.Module):\n",
        "    def __init__(self, model_name=\"bert-base-uncased\", num_labels=12):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        logits = self.classifier(self.dropout(pooled_output))\n",
        "        return logits\n",
        "\n",
        "def prepare_expanded_data(data, test_size=0.2, val_size=0.1):\n",
        "    \"\"\"Prepare data for training with expanded dataset.\"\"\"\n",
        "    print(\"\ud83d\udd27 Preparing expanded data...\")\n",
        "    \n",
        "    # Extract texts and emotions\n",
        "    texts = [entry['content'] for entry in data]\n",
        "    emotions = [entry['emotion'] for entry in data]\n",
        "    \n",
        "    # Create label encoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(emotions)\n",
        "    \n",
        "    print(f\"\u2705 Label encoder created with {len(label_encoder.classes_)} classes\")\n",
        "    print(f\"\ud83d\udcca Classes: {list(label_encoder.classes_)}\")\n",
        "    \n",
        "    # Split data\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        texts, labels, test_size=test_size, random_state=42, stratify=labels\n",
        "    )\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=val_size/(1-test_size), random_state=42, stratify=y_temp\n",
        "    )\n",
        "    \n",
        "    print(f\"\ud83d\udcca Data split:\")\n",
        "    print(f\"  Training: {len(X_train)} samples\")\n",
        "    print(f\"  Validation: {len(X_val)} samples\")\n",
        "    print(f\"  Test: {len(X_test)} samples\")\n",
        "    \n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), label_encoder\n",
        "\n",
        "def train_expanded_model(train_data, val_data, label_encoder, epochs=5, batch_size=16):\n",
        "    \"\"\"Train the model with expanded dataset and GPU optimizations.\"\"\"\n",
        "    print(\"\ud83d\ude80 Training with expanded dataset...\")\n",
        "    \n",
        "    # Setup\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\u2705 Using device: {device}\")\n",
        "    \n",
        "    # GPU optimizations\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"\ud83d\udd27 Applying GPU optimizations...\")\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        print(f\"\ud83d\udcca GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        print(f\"\ud83d\udcca Available Memory: {torch.cuda.memory_allocated(0) / 1e9:.1f} GB\")\n",
        "    \n",
        "    # Clear GPU cache\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    \n",
        "    # Create datasets\n",
        "    X_train, y_train = train_data\n",
        "    X_val, y_val = val_data\n",
        "    \n",
        "    train_dataset = ExpandedEmotionDataset(X_train, y_train, tokenizer)\n",
        "    val_dataset = ExpandedEmotionDataset(X_val, y_val, tokenizer)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    \n",
        "    # Initialize model\n",
        "    model = ExpandedEmotionClassifier(num_labels=len(label_encoder.classes_))\n",
        "    model.to(device)\n",
        "    \n",
        "    # Setup training with optimizations\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = GradScaler()\n",
        "    \n",
        "    # Training loop\n",
        "    best_f1 = 0\n",
        "    training_history = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n\ud83d\udd04 Epoch {epoch + 1}/{epochs}\")\n",
        "        \n",
        "        # Training\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        \n",
        "        for i, batch in enumerate(train_loader):\n",
        "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
        "            labels = batch['labels'].to(device, non_blocking=True)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Mixed precision training\n",
        "            with autocast():\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(outputs, labels)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            if i % 50 == 0:\n",
        "                print(f\"  Batch {i}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "                attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
        "                labels = batch['labels'].to(device, non_blocking=True)\n",
        "                \n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                \n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        \n",
        "        # Calculate metrics\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        \n",
        "        print(f\"\ud83d\udcca Epoch {epoch + 1} Results:\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"  Val F1 (Macro): {f1_macro:.4f}\")\n",
        "        print(f\"  Val Accuracy: {accuracy:.4f}\")\n",
        "        \n",
        "        # Early stopping check\n",
        "        if epoch > 2 and f1_macro < best_f1 * 0.95:\n",
        "            print(f\"\ud83d\uded1 Early stopping triggered. F1 dropped below 95% of best.\")\n",
        "            break\n",
        "        \n",
        "        # Save best model\n",
        "        if f1_macro > best_f1:\n",
        "            best_f1 = f1_macro\n",
        "            torch.save(model.state_dict(), 'best_expanded_model.pth')\n",
        "            print(f\"\ud83d\udcbe New best model saved! F1: {best_f1:.4f}\")\n",
        "            scheduler.step(f1_macro)\n",
        "        \n",
        "        training_history.append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': avg_train_loss,\n",
        "            'val_loss': avg_val_loss,\n",
        "            'val_f1_macro': f1_macro,\n",
        "            'val_accuracy': accuracy\n",
        "        })\n",
        "    \n",
        "    return model, training_history, best_f1\n",
        "\n",
        "# Load expanded dataset\n",
        "with open('data/expanded_journal_dataset.json', 'r') as f:\n",
        "    expanded_data = json.load(f)\n",
        "\n",
        "print(f\"\ud83d\udcca Loaded {len(expanded_data)} expanded samples\")\n",
        "\n",
        "# Prepare data\n",
        "train_data, val_data, test_data, label_encoder = prepare_expanded_data(expanded_data)\n",
        "\n",
        "# Train model\n",
        "model, training_history, best_f1 = train_expanded_model(train_data, val_data, label_encoder)\n",
        "\n",
        "print(f\"\\n\ud83c\udf89 Training completed!\")\n",
        "print(f\"\ud83d\udcca Best F1 Score: {best_f1:.4f}\")\n",
        "print(f\"\ud83c\udfaf Target Achieved: {best_f1 >= 0.70}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "testing"
      },
      "source": [
        "## \ud83e\uddea Test the New Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_new_model"
      },
      "outputs": [],
      "source": [
        "# Test the new model with sample entries\n",
        "def test_new_model():\n",
        "    \"\"\"Test the new model with sample journal entries.\"\"\"\n",
        "    print(\"\ud83e\uddea Testing new expanded model...\")\n",
        "    \n",
        "    # Load best model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = ExpandedEmotionClassifier(num_labels=len(label_encoder.classes_))\n",
        "    model.load_state_dict(torch.load('best_expanded_model.pth'))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    \n",
        "    # Sample test entries\n",
        "    test_entries = [\n",
        "        \"I'm feeling really happy today! Everything is going well.\",\n",
        "        \"I'm so frustrated with this project. Nothing is working.\",\n",
        "        \"I feel anxious about the upcoming presentation.\",\n",
        "        \"I'm grateful for all the support I've received.\",\n",
        "        \"I'm feeling overwhelmed with all these tasks.\",\n",
        "        \"I'm proud of what I've accomplished so far.\",\n",
        "        \"I'm feeling sad and lonely today.\",\n",
        "        \"I'm excited about the new opportunities ahead.\",\n",
        "        \"I feel calm and peaceful right now.\",\n",
        "        \"I'm hopeful that things will get better.\",\n",
        "        \"I'm tired and need some rest.\",\n",
        "        \"I'm content with how things are going.\"\n",
        "    ]\n",
        "    \n",
        "    print(\"\\n\ud83d\udcca Testing Results:\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for i, text in enumerate(test_entries, 1):\n",
        "        # Tokenize\n",
        "        encoding = tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        # Predict\n",
        "        with torch.no_grad():\n",
        "            input_ids = encoding['input_ids'].to(device)\n",
        "            attention_mask = encoding['attention_mask'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "            confidence = probabilities[0][predicted_class].item()\n",
        "        \n",
        "        # Get emotion label\n",
        "        emotion = label_encoder.inverse_transform([predicted_class])[0]\n",
        "        \n",
        "        print(f\"\\n{i}. Text: {text}\")\n",
        "        print(f\"   Predicted: {emotion} (confidence: {confidence:.3f})\")\n",
        "        \n",
        "        # Show top 3 predictions\n",
        "        all_probs = probabilities[0].cpu().numpy()\n",
        "        top_indices = np.argsort(all_probs)[-3:][::-1]\n",
        "        print(\"   Top 3 predictions:\")\n",
        "        for idx in top_indices:\n",
        "            prob = all_probs[idx]\n",
        "            emotion_name = label_encoder.inverse_transform([idx])[0]\n",
        "            print(f\"     - {emotion_name}: {prob:.3f}\")\n",
        "    \n",
        "    print(\"\\n\u2705 Model testing completed!\")\n",
        "\n",
        "# Test the new model\n",
        "test_new_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download"
      },
      "source": [
        "## \ud83d\udcbe Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "# Download the trained model and results\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\ud83d\udce5 Downloading results...\")\n",
        "\n",
        "# Download model\n",
        "files.download('best_expanded_model.pth')\n",
        "\n",
        "# Save and download results\n",
        "results = {\n",
        "    'best_f1': best_f1,\n",
        "    'target_achieved': best_f1 >= 0.70,\n",
        "    'num_labels': len(label_encoder.classes_),\n",
        "    'all_emotions': list(label_encoder.classes_),\n",
        "    'training_history': training_history,\n",
        "    'expanded_samples': len(expanded_data)\n",
        "}\n",
        "\n",
        "with open('expanded_training_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "files.download('expanded_training_results.json')\n",
        "\n",
        "print(\"\u2705 Downloads completed!\")\n",
        "print(f\"\ud83d\udcca Final F1 Score: {best_f1:.4f}\")\n",
        "print(f\"\ud83c\udfaf Target Achieved: {best_f1 >= 0.70}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
