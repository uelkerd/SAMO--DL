{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 COMPREHENSIVE ULTIMATE BULLETPROOF EMOTION DETECTION TRAINING\n",
        "## All Advanced Features + Technical Fixes\n",
        "\n",
        "**FEATURES INCLUDED:**\n",
        "\u2705 Configuration preservation (prevents 8.3% vs 75% discrepancy)\n",
        "\u2705 Focal loss (handles class imbalance)\n",
        "\u2705 Class weighting (WeightedLossTrainer)\n",
        "\u2705 Data augmentation (sophisticated techniques)\n",
        "\u2705 Advanced validation (proper testing)\n",
        "\u2705 WandB integration with secrets\n",
        "\u2705 Model architecture fixes\n",
        "\u2705 Comprehensive dataset\n",
        "\n",
        "**Target**: Reliable 75-85% F1 score with consistent performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch scikit-learn numpy pandas huggingface_hub wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('\u2705 All packages imported successfully')\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd11 WANDB API KEY SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup Weights & Biases API key from Google Colab secrets\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "print('\ud83d\udd11 SETTING UP WANDB API KEY')\n",
        "print('=' * 40)\n",
        "\n",
        "# Try to get API key from Colab secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    \n",
        "    # Try different possible secret names\n",
        "    possible_secret_names = [\n",
        "        'WANDB_API_KEY',\n",
        "        'wandb_api_key',\n",
        "        'WANDB_KEY',\n",
        "        'wandb_key',\n",
        "        'WANDB_TOKEN',\n",
        "        'wandb_token'\n",
        "    ]\n",
        "    \n",
        "    api_key = None\n",
        "    used_secret_name = None\n",
        "    \n",
        "    for secret_name in possible_secret_names:\n",
        "        try:\n",
        "            api_key = userdata.get(secret_name)\n",
        "            used_secret_name = secret_name\n",
        "            print(f'\u2705 Found API key in secret: {secret_name}')\n",
        "            break\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    if api_key:\n",
        "        # Set the environment variable\n",
        "        os.environ['WANDB_API_KEY'] = api_key\n",
        "        print(f'\u2705 API key set from secret: {used_secret_name}')\n",
        "        \n",
        "        # Test wandb login\n",
        "        try:\n",
        "            wandb.login(key=api_key)\n",
        "            print('\u2705 WandB login successful!')\n",
        "        except Exception as e:\n",
        "            print(f'\u26a0\ufe0f WandB login failed: {str(e)}')\n",
        "            print('Continuing without WandB...')\n",
        "    else:\n",
        "        print('\u274c No WandB API key found in secrets')\n",
        "        print('\\n\ud83d\udccb TO SET UP WANDB SECRET:')\n",
        "        print('1. Go to Colab \u2192 Settings \u2192 Secrets')\n",
        "        print('2. Add a new secret with name: WANDB_API_KEY')\n",
        "        print('3. Value: Your WandB API key from https://wandb.ai/authorize')\n",
        "        print('4. Restart runtime and run this cell again')\n",
        "        print('\\n\u26a0\ufe0f Continuing without WandB logging...')\n",
        "        \n",
        "except ImportError:\n",
        "    print('\u26a0\ufe0f Google Colab secrets not available')\n",
        "    print('\\n\ud83d\udccb TO SET UP WANDB:')\n",
        "    print('1. Get your API key from: https://wandb.ai/authorize')\n",
        "    print('2. Run: wandb login')\n",
        "    print('3. Enter your API key when prompted')\n",
        "    print('\\n\u26a0\ufe0f Continuing without WandB logging...')\n",
        "\n",
        "print('\\n\u2705 WandB setup completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd0d VERIFYING SPECIALIZED MODEL ACCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udd0d VERIFYING SPECIALIZED MODEL ACCESS')\n",
        "print('=' * 50)\n",
        "\n",
        "specialized_model_name = 'j-hartmann/emotion-english-distilroberta-base'\n",
        "\n",
        "try:\n",
        "    print(f'Testing access to: {specialized_model_name}')\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(specialized_model_name)\n",
        "    test_model = AutoModelForSequenceClassification.from_pretrained(specialized_model_name)\n",
        "    \n",
        "    print('\u2705 SUCCESS: Specialized model loaded!')\n",
        "    print(f'Model type: {test_model.config.model_type}')\n",
        "    print(f'Architecture: {test_model.config.architectures[0]}')\n",
        "    print(f'Hidden layers: {test_model.config.num_hidden_layers}')\n",
        "    print(f'Hidden size: {test_model.config.hidden_size}')\n",
        "    print(f'Number of labels: {test_model.config.num_labels}')\n",
        "    print(f'Original labels: {test_model.config.id2label}')\n",
        "    \n",
        "    # Verify it's actually DistilRoBERTa\n",
        "    if test_model.config.num_hidden_layers == 6:\n",
        "        print('\u2705 CONFIRMED: This is DistilRoBERTa architecture')\n",
        "    else:\n",
        "        print('\u26a0\ufe0f  WARNING: This may not be the expected DistilRoBERTa model')\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f'\u274c ERROR: Cannot access specialized model: {str(e)}')\n",
        "    print('\\n\ud83d\udd27 FALLBACK: Using roberta-base instead')\n",
        "    specialized_model_name = 'roberta-base'\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(specialized_model_name)\n",
        "    test_model = AutoModelForSequenceClassification.from_pretrained(specialized_model_name, num_labels=12)\n",
        "    print(f'\u2705 Fallback model loaded: {specialized_model_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf DEFINING EMOTION CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our emotion classes\n",
        "emotions = ['anxious', 'calm', 'content', 'excited', 'frustrated', 'grateful', 'happy', 'hopeful', 'overwhelmed', 'proud', 'sad', 'tired']\n",
        "print(f'\ud83c\udfaf Our emotion classes: {emotions}')\n",
        "print(f'\ud83d\udcca Number of emotions: {len(emotions)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca CREATING COMPREHENSIVE ENHANCED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udcca CREATING COMPREHENSIVE ENHANCED DATASET')\n",
        "print('=' * 50)\n",
        "\n",
        "# Comprehensive balanced dataset with multiple samples per emotion\n",
        "base_data = [\n",
        "    # anxious (20 samples)\n",
        "    {'text': 'I feel anxious about the presentation.', 'label': 0},\n",
        "    {'text': 'I am anxious about the future.', 'label': 0},\n",
        "    {'text': 'This makes me feel anxious.', 'label': 0},\n",
        "    {'text': 'I am feeling anxious today.', 'label': 0},\n",
        "    {'text': 'The uncertainty makes me anxious.', 'label': 0},\n",
        "    {'text': 'I feel anxious about the results.', 'label': 0},\n",
        "    {'text': 'This situation is making me anxious.', 'label': 0},\n",
        "    {'text': 'I am anxious about the meeting.', 'label': 0},\n",
        "    {'text': 'The pressure is making me anxious.', 'label': 0},\n",
        "    {'text': 'I feel anxious about the decision.', 'label': 0},\n",
        "    {'text': 'This is causing me anxiety.', 'label': 0},\n",
        "    {'text': 'I am anxious about the changes.', 'label': 0},\n",
        "    {'text': 'I feel worried about the outcome.', 'label': 0},\n",
        "    {'text': 'I am nervous about the interview.', 'label': 0},\n",
        "    {'text': 'This makes me feel uneasy.', 'label': 0},\n",
        "    {'text': 'I am concerned about the situation.', 'label': 0},\n",
        "    {'text': 'I feel tense about the deadline.', 'label': 0},\n",
        "    {'text': 'I am stressed about the project.', 'label': 0},\n",
        "    {'text': 'This gives me anxiety.', 'label': 0},\n",
        "    {'text': 'I feel restless about the future.', 'label': 0},\n",
        "    \n",
        "    # calm (20 samples)\n",
        "    {'text': 'I feel calm and peaceful.', 'label': 1},\n",
        "    {'text': 'I am feeling calm today.', 'label': 1},\n",
        "    {'text': 'This makes me feel calm.', 'label': 1},\n",
        "    {'text': 'I am calm about the situation.', 'label': 1},\n",
        "    {'text': 'I feel calm and relaxed.', 'label': 1},\n",
        "    {'text': 'This gives me a sense of calm.', 'label': 1},\n",
        "    {'text': 'I am feeling calm and centered.', 'label': 1},\n",
        "    {'text': 'This brings me calm.', 'label': 1},\n",
        "    {'text': 'I feel calm and at peace.', 'label': 1},\n",
        "    {'text': 'I am calm about the outcome.', 'label': 1},\n",
        "    {'text': 'This creates a feeling of calm.', 'label': 1},\n",
        "    {'text': 'I feel calm and collected.', 'label': 1},\n",
        "    {'text': 'I am feeling serene today.', 'label': 1},\n",
        "    {'text': 'This makes me feel tranquil.', 'label': 1},\n",
        "    {'text': 'I feel peaceful and relaxed.', 'label': 1},\n",
        "    {'text': 'This gives me inner peace.', 'label': 1},\n",
        "    {'text': 'I am feeling centered and calm.', 'label': 1},\n",
        "    {'text': 'This brings me tranquility.', 'label': 1},\n",
        "    {'text': 'I feel at ease with everything.', 'label': 1},\n",
        "    {'text': 'I am in a peaceful state of mind.', 'label': 1},\n",
        "    \n",
        "    # content (20 samples)\n",
        "    {'text': 'I feel content with my life.', 'label': 2},\n",
        "    {'text': 'I am content with the results.', 'label': 2},\n",
        "    {'text': 'This makes me feel content.', 'label': 2},\n",
        "    {'text': 'I am feeling content today.', 'label': 2},\n",
        "    {'text': 'I feel content and satisfied.', 'label': 2},\n",
        "    {'text': 'This gives me contentment.', 'label': 2},\n",
        "    {'text': 'I am content with my choices.', 'label': 2},\n",
        "    {'text': 'I feel content and fulfilled.', 'label': 2},\n",
        "    {'text': 'This brings me contentment.', 'label': 2},\n",
        "    {'text': 'I am content with the situation.', 'label': 2},\n",
        "    {'text': 'I feel content and at ease.', 'label': 2},\n",
        "    {'text': 'This creates contentment in me.', 'label': 2},\n",
        "    {'text': 'I am satisfied with my progress.', 'label': 2},\n",
        "    {'text': 'This makes me feel fulfilled.', 'label': 2},\n",
        "    {'text': 'I feel pleased with the outcome.', 'label': 2},\n",
        "    {'text': 'This gives me satisfaction.', 'label': 2},\n",
        "    {'text': 'I am happy with my current state.', 'label': 2},\n",
        "    {'text': 'I feel gratified with the results.', 'label': 2},\n",
        "    {'text': 'This brings me fulfillment.', 'label': 2},\n",
        "    {'text': 'I am at peace with my situation.', 'label': 2},\n",
        "    \n",
        "    # excited (20 samples)\n",
        "    {'text': 'I am excited about the new opportunity.', 'label': 3},\n",
        "    {'text': 'I feel excited about the future.', 'label': 3},\n",
        "    {'text': 'This makes me feel excited.', 'label': 3},\n",
        "    {'text': 'I am feeling excited today.', 'label': 3},\n",
        "    {'text': 'I feel excited and enthusiastic.', 'label': 3},\n",
        "    {'text': 'This gives me excitement.', 'label': 3},\n",
        "    {'text': 'I am excited about the project.', 'label': 3},\n",
        "    {'text': 'I feel excited and motivated.', 'label': 3},\n",
        "    {'text': 'This brings me excitement.', 'label': 3},\n",
        "    {'text': 'I am excited about the possibilities.', 'label': 3},\n",
        "    {'text': 'I feel excited and energized.', 'label': 3},\n",
        "    {'text': 'This creates excitement in me.', 'label': 3},\n",
        "    {'text': 'I am thrilled about the news.', 'label': 3},\n",
        "    {'text': 'This makes me feel enthusiastic.', 'label': 3},\n",
        "    {'text': 'I feel eager about the opportunity.', 'label': 3},\n",
        "    {'text': 'This gives me energy and motivation.', 'label': 3},\n",
        "    {'text': 'I am pumped about the challenge.', 'label': 3},\n",
        "    {'text': 'I feel energized by the possibilities.', 'label': 3},\n",
        "    {'text': 'This brings me enthusiasm.', 'label': 3},\n",
        "    {'text': 'I am looking forward to this.', 'label': 3},\n",
        "    \n",
        "    # frustrated (20 samples)\n",
        "    {'text': 'I am so frustrated with this project.', 'label': 4},\n",
        "    {'text': 'I feel frustrated about the situation.', 'label': 4},\n",
        "    {'text': 'This makes me feel frustrated.', 'label': 4},\n",
        "    {'text': 'I am feeling frustrated today.', 'label': 4},\n",
        "    {'text': 'I feel frustrated and annoyed.', 'label': 4},\n",
        "    {'text': 'This gives me frustration.', 'label': 4},\n",
        "    {'text': 'I am frustrated with the results.', 'label': 4},\n",
        "    {'text': 'I feel frustrated and irritated.', 'label': 4},\n",
        "    {'text': 'This brings me frustration.', 'label': 4},\n",
        "    {'text': 'I am frustrated with the process.', 'label': 4},\n",
        "    {'text': 'I feel frustrated and upset.', 'label': 4},\n",
        "    {'text': 'This creates frustration in me.', 'label': 4},\n",
        "    {'text': 'I am annoyed with the problems.', 'label': 4},\n",
        "    {'text': 'This makes me feel irritated.', 'label': 4},\n",
        "    {'text': 'I feel aggravated by the situation.', 'label': 4},\n",
        "    {'text': 'This gives me annoyance.', 'label': 4},\n",
        "    {'text': 'I am bothered by the issues.', 'label': 4},\n",
        "    {'text': 'I feel irritated with the process.', 'label': 4},\n",
        "    {'text': 'This brings me annoyance.', 'label': 4},\n",
        "    {'text': 'I am upset with the situation.', 'label': 4},\n",
        "    \n",
        "    # grateful (20 samples)\n",
        "    {'text': 'I am grateful for all the support.', 'label': 5},\n",
        "    {'text': 'I feel grateful for the opportunity.', 'label': 5},\n",
        "    {'text': 'This makes me feel grateful.', 'label': 5},\n",
        "    {'text': 'I am feeling grateful today.', 'label': 5},\n",
        "    {'text': 'I feel grateful and thankful.', 'label': 5},\n",
        "    {'text': 'This gives me gratitude.', 'label': 5},\n",
        "    {'text': 'I am grateful for the help.', 'label': 5},\n",
        "    {'text': 'I feel grateful and appreciative.', 'label': 5},\n",
        "    {'text': 'This brings me gratitude.', 'label': 5},\n",
        "    {'text': 'I am grateful for the kindness.', 'label': 5},\n",
        "    {'text': 'I feel grateful and blessed.', 'label': 5},\n",
        "    {'text': 'This creates gratitude in me.', 'label': 5},\n",
        "    {'text': 'I am thankful for the support.', 'label': 5},\n",
        "    {'text': 'This makes me feel appreciative.', 'label': 5},\n",
        "    {'text': 'I feel blessed by the opportunity.', 'label': 5},\n",
        "    {'text': 'This gives me appreciation.', 'label': 5},\n",
        "    {'text': 'I am indebted to the help.', 'label': 5},\n",
        "    {'text': 'I feel thankful for the kindness.', 'label': 5},\n",
        "    {'text': 'This brings me appreciation.', 'label': 5},\n",
        "    {'text': 'I am blessed with good fortune.', 'label': 5},\n",
        "    \n",
        "    # happy (20 samples)\n",
        "    {'text': 'I am feeling really happy today!', 'label': 6},\n",
        "    {'text': 'I feel happy about the news.', 'label': 6},\n",
        "    {'text': 'This makes me feel happy.', 'label': 6},\n",
        "    {'text': 'I am feeling happy today.', 'label': 6},\n",
        "    {'text': 'I feel happy and joyful.', 'label': 6},\n",
        "    {'text': 'This gives me happiness.', 'label': 6},\n",
        "    {'text': 'I am happy with the results.', 'label': 6},\n",
        "    {'text': 'I feel happy and delighted.', 'label': 6},\n",
        "    {'text': 'This brings me happiness.', 'label': 6},\n",
        "    {'text': 'I am happy about the success.', 'label': 6},\n",
        "    {'text': 'I feel happy and cheerful.', 'label': 6},\n",
        "    {'text': 'This creates happiness in me.', 'label': 6},\n",
        "    {'text': 'I am joyful about the completion.', 'label': 6},\n",
        "    {'text': 'This makes me feel delighted.', 'label': 6},\n",
        "    {'text': 'I feel cheerful about the outcome.', 'label': 6},\n",
        "    {'text': 'This gives me joy.', 'label': 6},\n",
        "    {'text': 'I am pleased with the results.', 'label': 6},\n",
        "    {'text': 'I feel delighted by the news.', 'label': 6},\n",
        "    {'text': 'This brings me joy.', 'label': 6},\n",
        "    {'text': 'I am cheerful about the future.', 'label': 6},\n",
        "    \n",
        "    # hopeful (20 samples)\n",
        "    {'text': 'I am hopeful for the future.', 'label': 7},\n",
        "    {'text': 'I feel hopeful about the outcome.', 'label': 7},\n",
        "    {'text': 'This makes me feel hopeful.', 'label': 7},\n",
        "    {'text': 'I am feeling hopeful today.', 'label': 7},\n",
        "    {'text': 'I feel hopeful and optimistic.', 'label': 7},\n",
        "    {'text': 'This gives me hope.', 'label': 7},\n",
        "    {'text': 'I am hopeful about the changes.', 'label': 7},\n",
        "    {'text': 'I feel hopeful and positive.', 'label': 7},\n",
        "    {'text': 'This brings me hope.', 'label': 7},\n",
        "    {'text': 'I am hopeful about the possibilities.', 'label': 7},\n",
        "    {'text': 'I feel hopeful and confident.', 'label': 7},\n",
        "    {'text': 'This creates hope in me.', 'label': 7},\n",
        "    {'text': 'I am optimistic about tomorrow.', 'label': 7},\n",
        "    {'text': 'This makes me feel positive.', 'label': 7},\n",
        "    {'text': 'I feel confident about the future.', 'label': 7},\n",
        "    {'text': 'This gives me optimism.', 'label': 7},\n",
        "    {'text': 'I am assured about the outcome.', 'label': 7},\n",
        "    {'text': 'I feel positive about the changes.', 'label': 7},\n",
        "    {'text': 'This brings me optimism.', 'label': 7},\n",
        "    {'text': 'I am confident about the possibilities.', 'label': 7},\n",
        "    \n",
        "    # overwhelmed (20 samples)\n",
        "    {'text': 'I am feeling overwhelmed with tasks.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed by the workload.', 'label': 8},\n",
        "    {'text': 'This makes me feel overwhelmed.', 'label': 8},\n",
        "    {'text': 'I am feeling overwhelmed today.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed and stressed.', 'label': 8},\n",
        "    {'text': 'This gives me overwhelm.', 'label': 8},\n",
        "    {'text': 'I am overwhelmed with responsibilities.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed and exhausted.', 'label': 8},\n",
        "    {'text': 'This brings me overwhelm.', 'label': 8},\n",
        "    {'text': 'I am overwhelmed with the pressure.', 'label': 8},\n",
        "    {'text': 'I feel overwhelmed and drained.', 'label': 8},\n",
        "    {'text': 'This creates overwhelm in me.', 'label': 8},\n",
        "    {'text': 'I am stressed with the workload.', 'label': 8},\n",
        "    {'text': 'This makes me feel burdened.', 'label': 8},\n",
        "    {'text': 'I feel swamped with tasks.', 'label': 8},\n",
        "    {'text': 'This gives me stress.', 'label': 8},\n",
        "    {'text': 'I am flooded with responsibilities.', 'label': 8},\n",
        "    {'text': 'I feel burdened by the pressure.', 'label': 8},\n",
        "    {'text': 'This brings me stress.', 'label': 8},\n",
        "    {'text': 'I am exhausted from the workload.', 'label': 8},\n",
        "    \n",
        "    # proud (20 samples)\n",
        "    {'text': 'I am proud of my accomplishments.', 'label': 9},\n",
        "    {'text': 'I feel proud of the results.', 'label': 9},\n",
        "    {'text': 'This makes me feel proud.', 'label': 9},\n",
        "    {'text': 'I am feeling proud today.', 'label': 9},\n",
        "    {'text': 'I feel proud and accomplished.', 'label': 9},\n",
        "    {'text': 'This gives me pride.', 'label': 9},\n",
        "    {'text': 'I am proud of my achievements.', 'label': 9},\n",
        "    {'text': 'I feel proud and satisfied.', 'label': 9},\n",
        "    {'text': 'This brings me pride.', 'label': 9},\n",
        "    {'text': 'I am proud of my progress.', 'label': 9},\n",
        "    {'text': 'I feel proud and confident.', 'label': 9},\n",
        "    {'text': 'This creates pride in me.', 'label': 9},\n",
        "    {'text': 'I am accomplished in my work.', 'label': 9},\n",
        "    {'text': 'This makes me feel satisfied.', 'label': 9},\n",
        "    {'text': 'I feel confident about my abilities.', 'label': 9},\n",
        "    {'text': 'This gives me confidence.', 'label': 9},\n",
        "    {'text': 'I am pleased with my performance.', 'label': 9},\n",
        "    {'text': 'I feel satisfied with my work.', 'label': 9},\n",
        "    {'text': 'This brings me satisfaction.', 'label': 9},\n",
        "    {'text': 'I am confident in my skills.', 'label': 9},\n",
        "    \n",
        "    # sad (20 samples)\n",
        "    {'text': 'I feel sad about the loss.', 'label': 10},\n",
        "    {'text': 'I am sad about the situation.', 'label': 10},\n",
        "    {'text': 'This makes me feel sad.', 'label': 10},\n",
        "    {'text': 'I am feeling sad today.', 'label': 10},\n",
        "    {'text': 'I feel sad and down.', 'label': 10},\n",
        "    {'text': 'This gives me sadness.', 'label': 10},\n",
        "    {'text': 'I am sad about the outcome.', 'label': 10},\n",
        "    {'text': 'I feel sad and depressed.', 'label': 10},\n",
        "    {'text': 'This brings me sadness.', 'label': 10},\n",
        "    {'text': 'I am sad about the news.', 'label': 10},\n",
        "    {'text': 'I feel sad and heartbroken.', 'label': 10},\n",
        "    {'text': 'This creates sadness in me.', 'label': 10},\n",
        "    {'text': 'I am down about the situation.', 'label': 10},\n",
        "    {'text': 'This makes me feel depressed.', 'label': 10},\n",
        "    {'text': 'I feel melancholy about the loss.', 'label': 10},\n",
        "    {'text': 'This gives me sorrow.', 'label': 10},\n",
        "    {'text': 'I am blue about the outcome.', 'label': 10},\n",
        "    {'text': 'I feel heartbroken by the news.', 'label': 10},\n",
        "    {'text': 'This brings me sorrow.', 'label': 10},\n",
        "    {'text': 'I am depressed about the situation.', 'label': 10},\n",
        "    \n",
        "    # tired (20 samples)\n",
        "    {'text': 'I am tired from working all day.', 'label': 11},\n",
        "    {'text': 'I feel tired of the routine.', 'label': 11},\n",
        "    {'text': 'This makes me feel tired.', 'label': 11},\n",
        "    {'text': 'I am feeling tired today.', 'label': 11},\n",
        "    {'text': 'I feel tired and exhausted.', 'label': 11},\n",
        "    {'text': 'This gives me fatigue.', 'label': 11},\n",
        "    {'text': 'I am tired of the stress.', 'label': 11},\n",
        "    {'text': 'I feel tired and worn out.', 'label': 11},\n",
        "    {'text': 'This brings me fatigue.', 'label': 11},\n",
        "    {'text': 'I am tired of the pressure.', 'label': 11},\n",
        "    {'text': 'I feel tired and drained.', 'label': 11},\n",
        "    {'text': 'This creates fatigue in me.', 'label': 11},\n",
        "    {'text': 'I am exhausted from the work.', 'label': 11},\n",
        "    {'text': 'This makes me feel fatigued.', 'label': 11},\n",
        "    {'text': 'I feel weary from the routine.', 'label': 11},\n",
        "    {'text': 'This gives me exhaustion.', 'label': 11},\n",
        "    {'text': 'I am drained from the stress.', 'label': 11},\n",
        "    {'text': 'I feel worn out from the pressure.', 'label': 11},\n",
        "    {'text': 'This brings me exhaustion.', 'label': 11},\n",
        "    {'text': 'I am fatigued from the workload.', 'label': 11}\n",
        "]\n",
        "\n",
        "print(f'\ud83d\udcca Base dataset size: {len(base_data)} samples')\n",
        "\n",
        "# Advanced data augmentation function\n",
        "def augment_text(text, emotion):\n",
        "    \"\"\"Create augmented versions of the text with sophisticated techniques.\"\"\"\n",
        "    augmented = []\n",
        "    \n",
        "    # Synonym replacement with emotion-specific synonyms\n",
        "    synonyms = {\n",
        "        'anxious': ['worried', 'nervous', 'concerned', 'uneasy', 'tense', 'stressed'],\n",
        "        'calm': ['peaceful', 'serene', 'tranquil', 'relaxed', 'composed', 'centered'],\n",
        "        'content': ['satisfied', 'fulfilled', 'pleased', 'happy', 'gratified', 'at ease'],\n",
        "        'excited': ['thrilled', 'enthusiastic', 'eager', 'pumped', 'energized', 'motivated'],\n",
        "        'frustrated': ['annoyed', 'irritated', 'aggravated', 'bothered', 'upset', 'angry'],\n",
        "        'grateful': ['thankful', 'appreciative', 'blessed', 'indebted', 'obliged', 'pleased'],\n",
        "        'happy': ['joyful', 'cheerful', 'delighted', 'pleased', 'glad', 'elated'],\n",
        "        'hopeful': ['optimistic', 'positive', 'confident', 'assured', 'encouraged', 'upbeat'],\n",
        "        'overwhelmed': ['stressed', 'burdened', 'swamped', 'flooded', 'exhausted', 'drained'],\n",
        "        'proud': ['accomplished', 'satisfied', 'confident', 'pleased', 'fulfilled', 'achieved'],\n",
        "        'sad': ['down', 'depressed', 'melancholy', 'blue', 'heartbroken', 'sorrowful'],\n",
        "        'tired': ['exhausted', 'fatigued', 'weary', 'drained', 'worn out', 'spent']\n",
        "    }\n",
        "    \n",
        "    # Create variations with synonyms (more sophisticated)\n",
        "    for synonym in synonyms.get(emotion, [emotion])[:3]:  # Use first 3 synonyms\n",
        "        new_text = text.replace(emotion, synonym)\n",
        "        if new_text != text:\n",
        "            augmented.append({'text': new_text, 'label': emotions.index(emotion)})\n",
        "    \n",
        "    # Add intensity variations with more variety\n",
        "    intensity_words = ['really', 'very', 'extremely', 'quite', 'somewhat', 'incredibly', 'absolutely']\n",
        "    for intensity in intensity_words[:3]:\n",
        "        if intensity not in text.lower():\n",
        "            new_text = f'I am {intensity} {emotion}.'\n",
        "            augmented.append({'text': new_text, 'label': emotions.index(emotion)})\n",
        "    \n",
        "    # Add context variations\n",
        "    contexts = [\n",
        "        f'Right now, I feel {emotion}.',\n",
        "        f'At this moment, I am {emotion}.',\n",
        "        f'Currently, I feel {emotion}.',\n",
        "        f'In this situation, I am {emotion}.'\n",
        "    ]\n",
        "    for context in contexts[:2]:\n",
        "        augmented.append({'text': context, 'label': emotions.index(emotion)})\n",
        "    \n",
        "    return augmented\n",
        "\n",
        "# Apply comprehensive augmentation\n",
        "augmented_data = []\n",
        "for item in base_data:\n",
        "    emotion = emotions[item['label']]\n",
        "    augmented = augment_text(item['text'], emotion)\n",
        "    augmented_data.extend(augmented)\n",
        "\n",
        "# Combine base and augmented data\n",
        "enhanced_data = base_data + augmented_data\n",
        "print(f'\ud83d\udcca Enhanced dataset size: {len(enhanced_data)} samples')\n",
        "print(f'\ud83d\udcca Augmentation added: {len(augmented_data)} samples')\n",
        "\n",
        "# Convert to lists for processing\n",
        "texts = [item['text'] for item in enhanced_data]\n",
        "labels = [item['label'] for item in enhanced_data]\n",
        "\n",
        "print(f'\u2705 Comprehensive dataset prepared with {len(texts)} samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 MODEL SETUP WITH ARCHITECTURE FIXES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model and tokenizer\n",
        "model_name = 'j-hartmann/emotion-english-distilroberta-base'\n",
        "print(f'\ud83d\udd27 Loading model: {model_name}')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(f'Original model labels: {AutoModelForSequenceClassification.from_pretrained(model_name).config.num_labels}')\n",
        "print(f'Original id2label: {AutoModelForSequenceClassification.from_pretrained(model_name).config.id2label}')\n",
        "\n",
        "# CRITICAL: Create a NEW model with correct configuration from scratch\n",
        "print('\\n\ud83d\udd27 CREATING NEW MODEL WITH CORRECT ARCHITECTURE')\n",
        "print('=' * 60)\n",
        "\n",
        "# Create a new model with the correct number of labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(emotions),  # Set to 12 emotions\n",
        "    ignore_mismatched_sizes=True  # Important: ignore size mismatches\n",
        ")\n",
        "\n",
        "# Configure the model properly\n",
        "model.config.num_labels = len(emotions)\n",
        "model.config.id2label = {i: emotion for i, emotion in enumerate(emotions)}\n",
        "model.config.label2id = {emotion: i for i, emotion in enumerate(emotions)}\n",
        "model.config.problem_type = 'single_label_classification'\n",
        "\n",
        "# Verify the configuration\n",
        "print(f'\u2705 Model created with {model.config.num_labels} labels')\n",
        "print(f'\u2705 New id2label: {model.config.id2label}')\n",
        "print(f'\u2705 Classifier output size: {model.classifier.out_proj.out_features}')\n",
        "print(f'\u2705 Problem type: {model.config.problem_type}')\n",
        "\n",
        "# Test the model with a sample input\n",
        "test_input = tokenizer('I feel happy today', return_tensors='pt', truncation=True, padding=True)\n",
        "with torch.no_grad():\n",
        "    test_output = model(**test_input)\n",
        "    print(f'\u2705 Test output shape: {test_output.logits.shape}')\n",
        "    print(f'\u2705 Expected shape: [1, {len(emotions)}]')\n",
        "    assert test_output.logits.shape[1] == len(emotions), f'Output shape mismatch: {test_output.logits.shape[1]} != {len(emotions)}'\n",
        "    print('\u2705 Model architecture verified!')\n",
        "\n",
        "# Move model to GPU\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to('cuda')\n",
        "    print('\u2705 Model moved to GPU')\n",
        "else:\n",
        "    print('\u26a0\ufe0f CUDA not available, model will run on CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca DATA PREPROCESSING AND SPLITTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udcca PREPROCESSING AND SPLITTING DATA')\n",
        "print('=' * 50)\n",
        "\n",
        "# Split the data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f'\ud83d\udcca Training samples: {len(train_texts)}')\n",
        "print(f'\ud83d\udcca Validation samples: {len(val_texts)}')\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = {'text': train_texts, 'label': train_labels}\n",
        "val_dataset = {'text': val_texts, 'label': val_labels}\n",
        "\n",
        "print('\u2705 Data split and prepared')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2696\ufe0f FOCAL LOSS AND CLASS WEIGHTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\u2696\ufe0f SETTING UP FOCAL LOSS AND CLASS WEIGHTING')\n",
        "print('=' * 60)\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "\n",
        "class_weights_tensor = torch.FloatTensor(class_weights)\n",
        "if torch.cuda.is_available():\n",
        "    class_weights_tensor = class_weights_tensor.cuda()\n",
        "\n",
        "print(f'\u2705 Class weights calculated: {class_weights}')\n",
        "print(f'\u2705 Class weights tensor shape: {class_weights_tensor.shape}')\n",
        "\n",
        "# Focal Loss implementation\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "    \n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = torch.nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "print('\u2705 Focal Loss class defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf WEIGHTED LOSS TRAINER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83c\udfaf CREATING WEIGHTED LOSS TRAINER')\n",
        "print('=' * 50)\n",
        "\n",
        "# Custom trainer with focal loss and class weighting\n",
        "class WeightedLossTrainer(Trainer):\n",
        "    def __init__(self, focal_alpha=1, focal_gamma=2, class_weights=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.focal_alpha = focal_alpha\n",
        "        self.focal_gamma = focal_gamma\n",
        "        self.class_weights = class_weights\n",
        "    \n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop('labels')\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        \n",
        "        # Focal Loss\n",
        "        ce_loss = torch.nn.functional.cross_entropy(logits, labels, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.focal_alpha * (1-pt)**self.focal_gamma * ce_loss\n",
        "        \n",
        "        # Apply class weights if provided\n",
        "        if self.class_weights is not None:\n",
        "            weighted_loss = focal_loss * self.class_weights[labels]\n",
        "            loss = weighted_loss.mean()\n",
        "        else:\n",
        "            loss = focal_loss.mean()\n",
        "        \n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "print('\u2705 WeightedLossTrainer created with focal loss and class weighting')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 DATA PREPROCESSING FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udd27 SETTING UP DATA PREPROCESSING')\n",
        "print('=' * 50)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    if 'label' in examples:\n",
        "        tokenized['labels'] = examples['label']\n",
        "    return tokenized\n",
        "\n",
        "# Apply preprocessing\n",
        "train_dataset_processed = preprocess_function(train_dataset)\n",
        "val_dataset_processed = preprocess_function(val_dataset)\n",
        "\n",
        "# Create data collator\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=tokenizer,\n",
        "    padding=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "print('\u2705 Data preprocessing completed')\n",
        "print('\u2705 Data collator created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2699\ufe0f TRAINING ARGUMENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\u2699\ufe0f CONFIGURING TRAINING ARGUMENTS')\n",
        "print('=' * 50)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./comprehensive_emotion_model',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        "    greater_is_better=True,\n",
        "    # Disable wandb if no API key is set\n",
        "    report_to=None if 'WANDB_API_KEY' not in os.environ else ['wandb']\n",
        ")\n",
        "\n",
        "print('\u2705 Training arguments configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca COMPUTE METRICS FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udcca SETTING UP COMPUTE METRICS')\n",
        "print('=' * 50)\n",
        "\n",
        "# Compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision = precision_score(labels, predictions, average='weighted')\n",
        "    recall = recall_score(labels, predictions, average='weighted')\n",
        "    \n",
        "    return {\n",
        "        'f1': f1,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "print('\u2705 Compute metrics function defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 TRAINING EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = WeightedLossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_processed,\n",
        "    eval_dataset=val_dataset_processed,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    focal_alpha=1,\n",
        "    focal_gamma=2,\n",
        "    class_weights=class_weights_tensor\n",
        ")\n",
        "\n",
        "print('\u2705 Trainer initialized')\n",
        "\n",
        "# Start training\n",
        "print('\ud83d\ude80 STARTING COMPREHENSIVE TRAINING')\n",
        "print('=' * 60)\n",
        "print(f'\ud83c\udfaf Target: 75-85% F1 score')\n",
        "print(f'\ud83d\udcca Training samples: {len(train_texts)}')\n",
        "print(f'\ud83e\uddea Validation samples: {len(val_texts)}')\n",
        "print(f'\u2696\ufe0f Using focal loss + class weighting')\n",
        "print(f'\ud83d\udd27 Model: {model_name}')\n",
        "print(f'\ud83d\udcc8 Data augmentation: {len(augmented_data)} samples added')\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print('\u2705 Training completed successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca EVALUATION AND VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udcca EVALUATING MODEL PERFORMANCE')\n",
        "print('=' * 50)\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print('\\n\ud83d\udcca EVALUATION RESULTS:')\n",
        "print('=' * 30)\n",
        "for key, value in eval_results.items():\n",
        "    print(f'{key}: {value:.4f}')\n",
        "\n",
        "# Detailed classification report\n",
        "print('\\n\ud83d\udccb DETAILED CLASSIFICATION REPORT:')\n",
        "print('=' * 40)\n",
        "predictions = trainer.predict(val_dataset_processed)\n",
        "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
        "true_labels = val_labels\n",
        "\n",
        "print(classification_report(true_labels, pred_labels, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd0d ADVANCED VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udd0d ADVANCED VALIDATION AND BIAS ANALYSIS')\n",
        "print('=' * 60)\n",
        "\n",
        "# Test on completely unseen examples\n",
        "unseen_examples = [\n",
        "    'I am feeling absolutely ecstatic about the promotion!',\n",
        "    'This situation is making me extremely anxious and worried.',\n",
        "    'I feel completely overwhelmed by all the responsibilities.',\n",
        "    'I am so grateful for all the support I received.',\n",
        "    'This makes me feel incredibly proud of my achievements.',\n",
        "    'I am feeling quite content with my current situation.',\n",
        "    'This gives me a lot of hope for the future.',\n",
        "    'I feel really tired after working all day.',\n",
        "    'I am sad about the recent loss.',\n",
        "    'This excites me about the possibilities ahead.'\n",
        "]\n",
        "\n",
        "print('\\n\ud83e\uddea TESTING ON UNSEEN EXAMPLES:')\n",
        "print('=' * 40)\n",
        "\n",
        "for i, example in enumerate(unseen_examples, 1):\n",
        "    inputs = tokenizer(example, return_tensors='pt', truncation=True, padding=True)\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
        "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "        confidence = probabilities[0][predicted_label].item()\n",
        "    \n",
        "    print(f'{i:2d}. \"{example}\"')\n",
        "    print(f'    \u2192 Predicted: {emotions[predicted_label]} (confidence: {confidence:.3f})')\n",
        "    print()\n",
        "\n",
        "# Bias analysis\n",
        "print('\\n\ud83d\udcca BIAS ANALYSIS:')\n",
        "print('=' * 30)\n",
        "print('Checking for prediction bias across emotions...')\n",
        "\n",
        "# Count predictions per emotion\n",
        "prediction_counts = {emotion: 0 for emotion in emotions}\n",
        "for pred in pred_labels:\n",
        "    prediction_counts[emotions[pred]] += 1\n",
        "\n",
        "print('\\nPrediction distribution:')\n",
        "for emotion, count in prediction_counts.items():\n",
        "    percentage = (count / len(pred_labels)) * 100\n",
        "    print(f'{emotion:12s}: {count:3d} ({percentage:5.1f}%)')\n",
        "\n",
        "print('\\n\u2705 Advanced validation completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcbe MODEL SAVING WITH VERIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\ud83d\udcbe SAVING MODEL WITH CONFIGURATION VERIFICATION')\n",
        "print('=' * 60)\n",
        "\n",
        "# Save the model\n",
        "model_save_path = './comprehensive_emotion_model_final'\n",
        "trainer.save_model(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "print(f'\u2705 Model saved to: {model_save_path}')\n",
        "\n",
        "# CRITICAL: Verify the saved configuration\n",
        "print('\\n\ud83d\udd0d VERIFYING SAVED MODEL CONFIGURATION:')\n",
        "print('=' * 50)\n",
        "\n",
        "# Load the saved model and check configuration\n",
        "saved_model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n",
        "saved_tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
        "\n",
        "print(f'\u2705 Saved model labels: {saved_model.config.num_labels}')\n",
        "print(f'\u2705 Saved id2label: {saved_model.config.id2label}')\n",
        "print(f'\u2705 Saved label2id: {saved_model.config.label2id}')\n",
        "print(f'\u2705 Saved problem_type: {saved_model.config.problem_type}')\n",
        "\n",
        "# Test the saved model\n",
        "test_input = saved_tokenizer('I feel happy today', return_tensors='pt', truncation=True, padding=True)\n",
        "with torch.no_grad():\n",
        "    test_output = saved_model(**test_input)\n",
        "    predicted_label = torch.argmax(test_output.logits, dim=1).item()\n",
        "    confidence = torch.softmax(test_output.logits, dim=1)[0][predicted_label].item()\n",
        "\n",
        "print(f'\\n\ud83e\uddea SAVED MODEL TEST:')\n",
        "print(f'Input: \"I feel happy today\"')\n",
        "print(f'Predicted: {saved_model.config.id2label[predicted_label]} (confidence: {confidence:.3f})')\n",
        "\n",
        "# Verify configuration persistence\n",
        "config_correct = (\n",
        "    saved_model.config.num_labels == len(emotions) and\n",
        "    saved_model.config.id2label == {i: emotion for i, emotion in enumerate(emotions)} and\n",
        "    saved_model.config.problem_type == 'single_label_classification'\n",
        ")\n",
        "\n",
        "if config_correct:\n",
        "    print('\\n\u2705 CONFIGURATION PERSISTENCE VERIFIED!')\n",
        "    print('\u2705 Model will work correctly in deployment')\n",
        "    print('\u2705 No more 8.3% vs 75% discrepancy!')\n",
        "else:\n",
        "    print('\\n\u274c CONFIGURATION PERSISTENCE FAILED!')\n",
        "    print('\u274c Model may have issues in deployment')\n",
        "\n",
        "print(f'\\n\ud83c\udf89 COMPREHENSIVE TRAINING COMPLETED!')\n",
        "print(f'\ud83d\udcc1 Model saved to: {model_save_path}')\n",
        "print(f'\ud83d\udcca Final F1 Score: {eval_results.get(\"eval_f1\", \"N/A\"):.4f}')\n",
        "print(f'\ud83d\udcca Final Accuracy: {eval_results.get(\"eval_accuracy\", \"N/A\"):.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
